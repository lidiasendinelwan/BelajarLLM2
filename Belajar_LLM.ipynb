{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMA0SothuiqWNv2DoL9GGfO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a97fa97720d746ae85014a1cf3344e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71802b86b93f40c59f6285c08837549f",
              "IPY_MODEL_9b7d157f394d43189797cd5ea01904db",
              "IPY_MODEL_7d99b9213d62463f90494cbf4b82724a"
            ],
            "layout": "IPY_MODEL_a27e87e3a85049519cd2912711188de1"
          }
        },
        "71802b86b93f40c59f6285c08837549f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b393dd98449f4ccdaea98fd60e3f60c5",
            "placeholder": "​",
            "style": "IPY_MODEL_23d6ea6ef8714c5d88029b2c6bd2d3ab",
            "value": "Downloading: 100%"
          }
        },
        "9b7d157f394d43189797cd5ea01904db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e6e0ab69bb64faaaf9aad98d62fbcbe",
            "max": 930,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fbd2cea6e104c0aacfffaa056aadbb2",
            "value": 930
          }
        },
        "7d99b9213d62463f90494cbf4b82724a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5be056183f35467d84be22c4cc4ac0f9",
            "placeholder": "​",
            "style": "IPY_MODEL_3e8a1d75d941403ebcf824aa2ca85b8b",
            "value": " 930/930 [00:00&lt;00:00, 57.5kB/s]"
          }
        },
        "a27e87e3a85049519cd2912711188de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b393dd98449f4ccdaea98fd60e3f60c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23d6ea6ef8714c5d88029b2c6bd2d3ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e6e0ab69bb64faaaf9aad98d62fbcbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fbd2cea6e104c0aacfffaa056aadbb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5be056183f35467d84be22c4cc4ac0f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e8a1d75d941403ebcf824aa2ca85b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dcd4ae0b00c4b90971a428014b65843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbe02ccfd1e44f2b928dd01f70ab72f0",
              "IPY_MODEL_0dc5e50a3a5149e8949329358bc0c774",
              "IPY_MODEL_e31213fe34044504a35da7e1a3c7895a"
            ],
            "layout": "IPY_MODEL_d19759d98af74b278c09eaed1a3bbbc8"
          }
        },
        "fbe02ccfd1e44f2b928dd01f70ab72f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a62e7f7ac93842bd9ab1edfcaf7808f8",
            "placeholder": "​",
            "style": "IPY_MODEL_9e23e29529464472b557e415732b42f8",
            "value": "Downloading: 100%"
          }
        },
        "0dc5e50a3a5149e8949329358bc0c774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36e3e71ec55d4c3f87732f462913f1fb",
            "max": 619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_953bd96cf3a5483fbc563247953080e2",
            "value": 619
          }
        },
        "e31213fe34044504a35da7e1a3c7895a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cc75c21953c4088a90c07140b96ce01",
            "placeholder": "​",
            "style": "IPY_MODEL_ba1ab08d96844cacaf71edd889b25fb6",
            "value": " 619/619 [00:00&lt;00:00, 43.2kB/s]"
          }
        },
        "d19759d98af74b278c09eaed1a3bbbc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a62e7f7ac93842bd9ab1edfcaf7808f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e23e29529464472b557e415732b42f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36e3e71ec55d4c3f87732f462913f1fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "953bd96cf3a5483fbc563247953080e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cc75c21953c4088a90c07140b96ce01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba1ab08d96844cacaf71edd889b25fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa3b51a4946244b1899033a2f66e2336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ca2d3f653a54740baa00122a99032ad",
              "IPY_MODEL_37e2471baa694dc3bc375ae1dec94715",
              "IPY_MODEL_c191818d9a3d4169b2f04640d28cd496"
            ],
            "layout": "IPY_MODEL_2ec402dd112c478d9d9f17b4a4b6f982"
          }
        },
        "1ca2d3f653a54740baa00122a99032ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4d70f7bdec74136b38dc3ed8bf568fe",
            "placeholder": "​",
            "style": "IPY_MODEL_eca16ba21f144692a5d49f3e27db4098",
            "value": "Downloading: 100%"
          }
        },
        "37e2471baa694dc3bc375ae1dec94715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d691ba42fb240a7b67d21ef8bf538ca",
            "max": 798156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6d5820f9af145ef9db2bdba5bad166a",
            "value": 798156
          }
        },
        "c191818d9a3d4169b2f04640d28cd496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a90c69766c74b5da79ab336f4a27060",
            "placeholder": "​",
            "style": "IPY_MODEL_ef5e7be0550e42539e2e597eb7c77d67",
            "value": " 779k/779k [00:00&lt;00:00, 3.17MB/s]"
          }
        },
        "2ec402dd112c478d9d9f17b4a4b6f982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d70f7bdec74136b38dc3ed8bf568fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eca16ba21f144692a5d49f3e27db4098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d691ba42fb240a7b67d21ef8bf538ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6d5820f9af145ef9db2bdba5bad166a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a90c69766c74b5da79ab336f4a27060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef5e7be0550e42539e2e597eb7c77d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f90b41e1964072b43ff26adb07b86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40382cdf9e3a4579a45d359fbbaa36ce",
              "IPY_MODEL_f5f56b1359554745901c7d335ad00052",
              "IPY_MODEL_6ff734b61e83423a956f8b7e34647010"
            ],
            "layout": "IPY_MODEL_7aad97c5ea38440e8cbd5e06355150c3"
          }
        },
        "40382cdf9e3a4579a45d359fbbaa36ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8cc9a4b661544a4b0dcf454249f256a",
            "placeholder": "​",
            "style": "IPY_MODEL_e6008157c5f241eba75eb2ad7217b1a7",
            "value": "Downloading: 100%"
          }
        },
        "f5f56b1359554745901c7d335ad00052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_002780a964fd4278818b9ed6590b4164",
            "max": 456356,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_310768d7d8cf4654b7b345bcc9c17af8",
            "value": 456356
          }
        },
        "6ff734b61e83423a956f8b7e34647010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_502d6f870e3d41528384340e8daf0f18",
            "placeholder": "​",
            "style": "IPY_MODEL_bf132265009543a899d54d69c1787008",
            "value": " 446k/446k [00:00&lt;00:00, 2.49MB/s]"
          }
        },
        "7aad97c5ea38440e8cbd5e06355150c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8cc9a4b661544a4b0dcf454249f256a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6008157c5f241eba75eb2ad7217b1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "002780a964fd4278818b9ed6590b4164": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "310768d7d8cf4654b7b345bcc9c17af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "502d6f870e3d41528384340e8daf0f18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf132265009543a899d54d69c1787008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4c0edf6066944eaa4bcbeba46556ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46195e18798441e4a4f03f3ad776da22",
              "IPY_MODEL_0032f15a435e4202a3a94704db790707",
              "IPY_MODEL_82ec472bfdcd4965b3630bea8079d2df"
            ],
            "layout": "IPY_MODEL_ef30479ecda244ed8883d6e54182a210"
          }
        },
        "46195e18798441e4a4f03f3ad776da22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27eef1af3f604a388e66c00fafdbdce8",
            "placeholder": "​",
            "style": "IPY_MODEL_a40c5c7fc2a6444fa9dea25d1970c926",
            "value": "Downloading: 100%"
          }
        },
        "0032f15a435e4202a3a94704db790707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_960b3df38662448fa424af289a0f1597",
            "max": 1373465,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c0088dd1ade4cffa3fbc51b8490467b",
            "value": 1373465
          }
        },
        "82ec472bfdcd4965b3630bea8079d2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87687e1a6fa54332a6d7a3b31b0bf52b",
            "placeholder": "​",
            "style": "IPY_MODEL_60e3cfe12ac14ecd8cdedc2ed8840950",
            "value": " 1.31M/1.31M [00:00&lt;00:00, 4.83MB/s]"
          }
        },
        "ef30479ecda244ed8883d6e54182a210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27eef1af3f604a388e66c00fafdbdce8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a40c5c7fc2a6444fa9dea25d1970c926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "960b3df38662448fa424af289a0f1597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c0088dd1ade4cffa3fbc51b8490467b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87687e1a6fa54332a6d7a3b31b0bf52b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e3cfe12ac14ecd8cdedc2ed8840950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf5ac303955d4d838f108679125515b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fedc4ce862d46e38a69300f36680975",
              "IPY_MODEL_bc5b0a720b4d427bbc8e08fbef5c412a",
              "IPY_MODEL_329e20a67d2142a09bdada138044dea0"
            ],
            "layout": "IPY_MODEL_584c67008c974238956fd1c2820c2e31"
          }
        },
        "6fedc4ce862d46e38a69300f36680975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b38f019c9de344fb9b63d419061051cb",
            "placeholder": "​",
            "style": "IPY_MODEL_1057f8cec73a4e63a6bfa632f460a96e",
            "value": "Downloading: 100%"
          }
        },
        "bc5b0a720b4d427bbc8e08fbef5c412a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f2050be06a143988093d44b401db978",
            "max": 4039,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cc4cb9965174a8f95200ea2733dc17b",
            "value": 4039
          }
        },
        "329e20a67d2142a09bdada138044dea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e56412a3abba4da59344b9095daad31b",
            "placeholder": "​",
            "style": "IPY_MODEL_7d437f6e55ad4e818edb9b09007770d6",
            "value": " 3.94k/3.94k [00:00&lt;00:00, 177kB/s]"
          }
        },
        "584c67008c974238956fd1c2820c2e31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b38f019c9de344fb9b63d419061051cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1057f8cec73a4e63a6bfa632f460a96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f2050be06a143988093d44b401db978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cc4cb9965174a8f95200ea2733dc17b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e56412a3abba4da59344b9095daad31b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d437f6e55ad4e818edb9b09007770d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c052fe1880e4ac6b0a2a50b7cff8d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59d518468e054ef8adb20e115892827b",
              "IPY_MODEL_d9e24e208aaa42e89d3dbade324b66f4",
              "IPY_MODEL_b9bba4c064b04211930dd790672c79bf"
            ],
            "layout": "IPY_MODEL_0eb9d9b2532c4fd6a7dced63a7ec43c9"
          }
        },
        "59d518468e054ef8adb20e115892827b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c79007224c9643b1a344f0728342070f",
            "placeholder": "​",
            "style": "IPY_MODEL_25d71674406f40fba7e2ad9f4e74dce9",
            "value": "Downloading: 100%"
          }
        },
        "d9e24e208aaa42e89d3dbade324b66f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f4a988b59e4477d97ec31ffbd2e9e6b",
            "max": 357,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0243ebbe1be140838fe9814c0bbb7809",
            "value": 357
          }
        },
        "b9bba4c064b04211930dd790672c79bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1600008ac57a457882c5d3049e4b6d3b",
            "placeholder": "​",
            "style": "IPY_MODEL_fdd3f7e8d79d4032ad76cd63a32279e9",
            "value": " 357/357 [00:00&lt;00:00, 16.2kB/s]"
          }
        },
        "0eb9d9b2532c4fd6a7dced63a7ec43c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c79007224c9643b1a344f0728342070f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d71674406f40fba7e2ad9f4e74dce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f4a988b59e4477d97ec31ffbd2e9e6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0243ebbe1be140838fe9814c0bbb7809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1600008ac57a457882c5d3049e4b6d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdd3f7e8d79d4032ad76cd63a32279e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17ae860e9f474cdbb17756fa8c5f17fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a79f948797c94c4c8d8018922e116558",
              "IPY_MODEL_4b75975a20464e72877818d4908e1ebe",
              "IPY_MODEL_397b93fdfc204be59ab5d9dce6c57fc3"
            ],
            "layout": "IPY_MODEL_bb2b63cf77df44cf885ecd377628ced6"
          }
        },
        "a79f948797c94c4c8d8018922e116558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_542981591fa847829db3081483b41f5b",
            "placeholder": "​",
            "style": "IPY_MODEL_eb407742d5ab4686b10558f32d1a7517",
            "value": "Downloading: 100%"
          }
        },
        "4b75975a20464e72877818d4908e1ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbd26656034a492fa011f66cab670b9a",
            "max": 1021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c2111c4da6343bb9d562685eb4cb097",
            "value": 1021
          }
        },
        "397b93fdfc204be59ab5d9dce6c57fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_981ec643c0c844c4b94eb94e4050f549",
            "placeholder": "​",
            "style": "IPY_MODEL_955e735b4dc5485cb9dab29a55e42b78",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 62.8kB/s]"
          }
        },
        "bb2b63cf77df44cf885ecd377628ced6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "542981591fa847829db3081483b41f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb407742d5ab4686b10558f32d1a7517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbd26656034a492fa011f66cab670b9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c2111c4da6343bb9d562685eb4cb097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "981ec643c0c844c4b94eb94e4050f549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "955e735b4dc5485cb9dab29a55e42b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1552f07c39f04cfb94307b59e8c94e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b5f7ccb08084ce98a52fab5b6d6b062",
              "IPY_MODEL_9ab478afa3bf4d8f87a9ce2990c23f83",
              "IPY_MODEL_5a15955e1aac475b9d11e518bbf2fa8d"
            ],
            "layout": "IPY_MODEL_443f319f816a422ab89b079c004aeed1"
          }
        },
        "2b5f7ccb08084ce98a52fab5b6d6b062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71cd5a62af8047b5a1a7d9f1f2ad85e2",
            "placeholder": "​",
            "style": "IPY_MODEL_812617ac1eeb42deafac190f93d6df39",
            "value": "Downloading: 100%"
          }
        },
        "9ab478afa3bf4d8f87a9ce2990c23f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4b613632fbc4494ae6e842db1583742",
            "max": 6177012613,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc42cdf19df6400f8b468ef7ba2b14a2",
            "value": 6177012613
          }
        },
        "5a15955e1aac475b9d11e518bbf2fa8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd29a64fdb8d4be18273e7d8f3e3f9e5",
            "placeholder": "​",
            "style": "IPY_MODEL_e5957e77f6fa4de2a4d308816354272e",
            "value": " 5.75G/5.75G [01:35&lt;00:00, 50.1MB/s]"
          }
        },
        "443f319f816a422ab89b079c004aeed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71cd5a62af8047b5a1a7d9f1f2ad85e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "812617ac1eeb42deafac190f93d6df39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4b613632fbc4494ae6e842db1583742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc42cdf19df6400f8b468ef7ba2b14a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd29a64fdb8d4be18273e7d8f3e3f9e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5957e77f6fa4de2a4d308816354272e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3caced0d3704481da0da5baaaa114d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f900f96c2eed4278a279e2db0e9c4121",
              "IPY_MODEL_829cbe4c5af146e2a2774ca82bf702a1",
              "IPY_MODEL_478873d35e5a4a49bae11ef3c1d0b402"
            ],
            "layout": "IPY_MODEL_dee774a7ffa54e9bb352704bfe58fc77"
          }
        },
        "f900f96c2eed4278a279e2db0e9c4121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06b816fa81284ac8afd181ee845f6264",
            "placeholder": "​",
            "style": "IPY_MODEL_fc4d53bf0f4e4f38bf4a88de768cde03",
            "value": "100%"
          }
        },
        "829cbe4c5af146e2a2774ca82bf702a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_427ec3c6e4bb41b7887628ee6e9f01a7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_feb7917df7f7408e9dc5e362fcbb5115",
            "value": 1
          }
        },
        "478873d35e5a4a49bae11ef3c1d0b402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b5e02346ae24e4ba2f0eeff146ff478",
            "placeholder": "​",
            "style": "IPY_MODEL_1679795e195746c88acc6f823c60e640",
            "value": " 1/1 [00:00&lt;00:00, 51.27it/s]"
          }
        },
        "dee774a7ffa54e9bb352704bfe58fc77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06b816fa81284ac8afd181ee845f6264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc4d53bf0f4e4f38bf4a88de768cde03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "427ec3c6e4bb41b7887628ee6e9f01a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feb7917df7f7408e9dc5e362fcbb5115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b5e02346ae24e4ba2f0eeff146ff478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1679795e195746c88acc6f823c60e640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1258d508b314da0aa71c96267a19e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_239dccdd25d24af3a641d15f7476c990",
              "IPY_MODEL_89f4c9b019c4432ba46e4f0ecba12e9f",
              "IPY_MODEL_0ea906785629497eaed5d80c6ac41d15"
            ],
            "layout": "IPY_MODEL_c4cabc25bf2e42b09148c9e1930c09e7"
          }
        },
        "239dccdd25d24af3a641d15f7476c990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_755d53e43b224bc098655795369af689",
            "placeholder": "​",
            "style": "IPY_MODEL_4531fc438fed43538db156b884e413a1",
            "value": "100%"
          }
        },
        "89f4c9b019c4432ba46e4f0ecba12e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f897b8f8bc4e36a380f7c993cec403",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69cd3856b2774c31a634a6d57c00588a",
            "value": 1
          }
        },
        "0ea906785629497eaed5d80c6ac41d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30c9c548920c4f6ea5b76ccf3f8d0682",
            "placeholder": "​",
            "style": "IPY_MODEL_f43a05f679954fd0a714118b17a53402",
            "value": " 1/1 [00:00&lt;00:00, 39.28it/s]"
          }
        },
        "c4cabc25bf2e42b09148c9e1930c09e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "755d53e43b224bc098655795369af689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4531fc438fed43538db156b884e413a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69f897b8f8bc4e36a380f7c993cec403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69cd3856b2774c31a634a6d57c00588a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30c9c548920c4f6ea5b76ccf3f8d0682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43a05f679954fd0a714118b17a53402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c61a0e30cb354e19a2350a73f17ad635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b805d968fe94da1a63730318ea7a685",
              "IPY_MODEL_cecb879ef4d54c58a93f49b845b2029a",
              "IPY_MODEL_a3bcca7e819a4589b7abafb9e33aeba7"
            ],
            "layout": "IPY_MODEL_0e46f5807d1444efb41a9ccbf19d315f"
          }
        },
        "5b805d968fe94da1a63730318ea7a685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f519d78f0b5444b2ae6b81eb749bac9d",
            "placeholder": "​",
            "style": "IPY_MODEL_2073fc76a311420bb6c73e04c1da2057",
            "value": "100%"
          }
        },
        "cecb879ef4d54c58a93f49b845b2029a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54890cc2bf694de5a4482de2d6495fc5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eee0ac813dcf4c7d8d80175775a0333a",
            "value": 1
          }
        },
        "a3bcca7e819a4589b7abafb9e33aeba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cf0e6346238429baad647cadac1878e",
            "placeholder": "​",
            "style": "IPY_MODEL_5fdfc7049566472c88e723a09f11de60",
            "value": " 1/1 [00:00&lt;00:00, 35.92it/s]"
          }
        },
        "0e46f5807d1444efb41a9ccbf19d315f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f519d78f0b5444b2ae6b81eb749bac9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2073fc76a311420bb6c73e04c1da2057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54890cc2bf694de5a4482de2d6495fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eee0ac813dcf4c7d8d80175775a0333a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cf0e6346238429baad647cadac1878e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fdfc7049566472c88e723a09f11de60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f29c63837b6b4a7da7ebd01d3a6a8328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61a656fcf7334729898bb0c6b8977692",
              "IPY_MODEL_3cec74bbc2e74f7dafa874b89a5430aa",
              "IPY_MODEL_16f6ee1d4919412e8fceb4eead2af10b"
            ],
            "layout": "IPY_MODEL_b4e0fd1db62c44c2969aef20bdb10987"
          }
        },
        "61a656fcf7334729898bb0c6b8977692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85d31c01b4774477a612da269cb5843e",
            "placeholder": "​",
            "style": "IPY_MODEL_5d6143b7586b48059efae07e229a746a",
            "value": "100%"
          }
        },
        "3cec74bbc2e74f7dafa874b89a5430aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab7e55e60f8c44f1a23d6378e68fdeb6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13c699a92fec47c4881f131c5e707529",
            "value": 1
          }
        },
        "16f6ee1d4919412e8fceb4eead2af10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1e49badb1e34579b7e1a1b7efceac21",
            "placeholder": "​",
            "style": "IPY_MODEL_3e511cc729be4128aa5bead005153678",
            "value": " 1/1 [00:00&lt;00:00,  4.81ba/s]"
          }
        },
        "b4e0fd1db62c44c2969aef20bdb10987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85d31c01b4774477a612da269cb5843e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d6143b7586b48059efae07e229a746a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab7e55e60f8c44f1a23d6378e68fdeb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13c699a92fec47c4881f131c5e707529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1e49badb1e34579b7e1a1b7efceac21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e511cc729be4128aa5bead005153678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce33ab792ce140e798a16733326df896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e2da550410e4ce584d01f230aa86aac",
              "IPY_MODEL_04d097bdba3842f2b0f19fdf88cc3c59",
              "IPY_MODEL_db677177b7954606883e49a8cda799d3"
            ],
            "layout": "IPY_MODEL_b9a2f5cf892f4b6daf2eadf866830852"
          }
        },
        "2e2da550410e4ce584d01f230aa86aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdaecdea645b4e81acd65a685c45b661",
            "placeholder": "​",
            "style": "IPY_MODEL_2a81192b51ec40c08d003930425597fa",
            "value": "100%"
          }
        },
        "04d097bdba3842f2b0f19fdf88cc3c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45468f1c3a744c67bc5548aae76636ec",
            "max": 680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_141474c0f6d9403c93e7a7c24b79250d",
            "value": 680
          }
        },
        "db677177b7954606883e49a8cda799d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2173f65886b94747977e3342c996910d",
            "placeholder": "​",
            "style": "IPY_MODEL_e946fe5d89a441dfb4781339ca53dcdd",
            "value": " 680/680 [1:24:41&lt;00:00,  6.45s/it]"
          }
        },
        "b9a2f5cf892f4b6daf2eadf866830852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdaecdea645b4e81acd65a685c45b661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a81192b51ec40c08d003930425597fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45468f1c3a744c67bc5548aae76636ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "141474c0f6d9403c93e7a7c24b79250d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2173f65886b94747977e3342c996910d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e946fe5d89a441dfb4781339ca53dcdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lidiasendinelwan/BelajarLLM2/blob/main/Belajar_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js400F-xmpGL",
        "outputId": "4fe68404-1844-4f85-a08b-041759c597c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "Collecting transformers==4.18\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.18) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0 (from transformers==4.18)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.18) (2.31.0)\n",
            "Collecting sacremoses (from transformers==4.18)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.18)\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18) (2023.7.22)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18) (1.3.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=7d750421798f3ae30b8fc6e63a1c7f072534b96d6dbebfa304686847c9cf4ca0\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.41.1\n",
            "Collecting datasets==1.16.1\n",
            "  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.3/298.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==1.16.1) (1.23.5)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.16.1) (9.0.0)\n",
            "Collecting dill (from datasets==1.16.1)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==1.16.1) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.16.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==1.16.1) (4.66.1)\n",
            "Collecting xxhash (from datasets==1.16.1)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets==1.16.1)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.16.1) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==1.16.1) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.16.1) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==1.16.1) (23.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.16.1) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.16.1) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.16.1) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.16.1) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.16.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.16.1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.16.1) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.16.1) (3.12.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.16.1) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.16.1) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.16.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.16.1) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.16.1) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==1.16.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==1.16.1) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==1.16.1) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-1.16.1 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.22.0\n"
          ]
        }
      ],
      "source": [
        "#@title Install Depedencies\n",
        "!python --version\n",
        "!pip install transformers==4.18\n",
        "!pip install bitsandbytes\n",
        "!pip install datasets==1.16.1\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import transformers\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.cuda.amp import custom_fwd, custom_bwd\n",
        "\n",
        "from bitsandbytes.functional import quantize_blockwise, dequantize_blockwise\n",
        "\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "N65r0M2sm0F7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj2XdliNm0QI",
        "outputId": "46c3c7ba-cdee-45ed-aceb-b8bf5ed4dc4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FrozenBNBLinear(nn.Module):\n",
        "    def __init__(self, weight, absmax, code, bias=None):\n",
        "        assert isinstance(bias, nn.Parameter) or bias is None\n",
        "        super().__init__()\n",
        "        self.out_features, self.in_features = weight.shape\n",
        "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
        "        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n",
        "        self.register_buffer(\"code\", code.requires_grad_(False))\n",
        "        self.adapter = None\n",
        "        self.bias = bias\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = DequantizeAndLinear.apply(input, self.weight, self.absmax, self.code, self.bias)\n",
        "        output_clone = output.clone()\n",
        "        if self.adapter:\n",
        "            output_clone += self.adapter(input)\n",
        "        return output_clone\n",
        "\n",
        "    @classmethod\n",
        "    def from_linear(cls, linear: nn.Linear) -> \"FrozenBNBLinear\":\n",
        "        weights_int8, state = quantize_blockise_lowmemory(linear.weight)\n",
        "        return cls(weights_int8, *state, linear.bias)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{self.__class__.__name__}({self.in_features}, {self.out_features})\"\n",
        "\n",
        "\n",
        "class DequantizeAndLinear(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    @custom_fwd\n",
        "    def forward(ctx, input: torch.Tensor, weights_quantized: torch.ByteTensor,\n",
        "                absmax: torch.FloatTensor, code: torch.FloatTensor, bias: torch.FloatTensor):\n",
        "        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n",
        "        ctx.save_for_backward(input, weights_quantized, absmax, code)\n",
        "        ctx._has_bias = bias is not None\n",
        "        return F.linear(input, weights_deq, bias)\n",
        "\n",
        "    @staticmethod\n",
        "    @custom_bwd\n",
        "    def backward(ctx, grad_output: torch.Tensor):\n",
        "        assert not ctx.needs_input_grad[1] and not ctx.needs_input_grad[2] and not ctx.needs_input_grad[3]\n",
        "        input, weights_quantized, absmax, code = ctx.saved_tensors\n",
        "        # grad_output: [*batch, out_features]\n",
        "        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n",
        "        grad_input = grad_output @ weights_deq\n",
        "        grad_bias = grad_output.flatten(0, -2).sum(dim=0) if ctx._has_bias else None\n",
        "        return grad_input, None, None, None, grad_bias\n",
        "\n",
        "\n",
        "class FrozenBNBEmbedding(nn.Module):\n",
        "    def __init__(self, weight, absmax, code):\n",
        "        super().__init__()\n",
        "        self.num_embeddings, self.embedding_dim = weight.shape\n",
        "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
        "        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n",
        "        self.register_buffer(\"code\", code.requires_grad_(False))\n",
        "        self.adapter = None\n",
        "\n",
        "    def forward(self, input, **kwargs):\n",
        "        with torch.no_grad():\n",
        "            # note: both quantuized weights and input indices are *not* differentiable\n",
        "            weight_deq = dequantize_blockwise(self.weight, absmax=self.absmax, code=self.code)\n",
        "            output = F.embedding(input, weight_deq, **kwargs)\n",
        "        if self.adapter:\n",
        "            output += self.adapter(input)\n",
        "        return output\n",
        "\n",
        "    @classmethod\n",
        "    def from_embedding(cls, embedding: nn.Embedding) -> \"FrozenBNBEmbedding\":\n",
        "        weights_int8, state = quantize_blockise_lowmemory(embedding.weight)\n",
        "        return cls(weights_int8, *state)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{self.__class__.__name__}({self.num_embeddings}, {self.embedding_dim})\"\n",
        "\n",
        "\n",
        "def quantize_blockise_lowmemory(matrix: torch.Tensor, chunk_size: int = 2 ** 20):\n",
        "    assert chunk_size % 4096 == 0\n",
        "    code = None\n",
        "    chunks = []\n",
        "    absmaxes = []\n",
        "    flat_tensor = matrix.view(-1)\n",
        "    for i in range((matrix.numel() - 1) // chunk_size + 1):\n",
        "        input_chunk = flat_tensor[i * chunk_size: (i + 1) * chunk_size].clone()\n",
        "        quantized_chunk, (absmax_chunk, code) = quantize_blockwise(input_chunk, code=code)\n",
        "        chunks.append(quantized_chunk)\n",
        "        absmaxes.append(absmax_chunk)\n",
        "\n",
        "    matrix_i8 = torch.cat(chunks).reshape_as(matrix)\n",
        "    absmax = torch.cat(absmaxes)\n",
        "    return matrix_i8, (absmax, code)\n",
        "\n",
        "\n",
        "def convert_to_int8(model):\n",
        "    \"\"\"Convert linear and embedding modules to 8-bit with optional adapters\"\"\"\n",
        "    for module in list(model.modules()):\n",
        "        for name, child in module.named_children():\n",
        "            if isinstance(child, nn.Linear):\n",
        "                print(name, child)\n",
        "                setattr(\n",
        "                    module,\n",
        "                    name,\n",
        "                    FrozenBNBLinear(\n",
        "                        weight=torch.zeros(child.out_features, child.in_features, dtype=torch.uint8),\n",
        "                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n",
        "                        code=torch.zeros(256),\n",
        "                        bias=child.bias,\n",
        "                    ),\n",
        "                )\n",
        "            elif isinstance(child, nn.Embedding):\n",
        "                setattr(\n",
        "                    module,\n",
        "                    name,\n",
        "                    FrozenBNBEmbedding(\n",
        "                        weight=torch.zeros(child.num_embeddings, child.embedding_dim, dtype=torch.uint8),\n",
        "                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n",
        "                        code=torch.zeros(256),\n",
        "                    )\n",
        "                )"
      ],
      "metadata": {
        "id": "Bhe8ko0Ym0VY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTJBlock(transformers.models.gptj.modeling_gptj.GPTJBlock):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        convert_to_int8(self.attn)\n",
        "        convert_to_int8(self.mlp)\n",
        "\n",
        "\n",
        "class GPTJModel(transformers.models.gptj.modeling_gptj.GPTJModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        convert_to_int8(self)\n",
        "\n",
        "\n",
        "class GPTJForCausalLM(transformers.models.gptj.modeling_gptj.GPTJForCausalLM):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        convert_to_int8(self)\n",
        "\n",
        "\n",
        "transformers.models.gptj.modeling_gptj.GPTJBlock = GPTJBlock"
      ],
      "metadata": {
        "id": "4NpLEbUVn92F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class T5ForConditionalGeneration(transformers.models.t5.modeling_t5.T5ForConditionalGeneration):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        # convert_to_int8(self)\n",
        "\n",
        "transformers.models.t5.modeling_t5.T5ForConditionalGeneration = T5ForConditionalGeneration"
      ],
      "metadata": {
        "id": "jIdmHaEQm0bp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = transformers.GPTJConfig.from_pretrained(\"EleutherAI/gpt-j-6b\")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6b\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "a97fa97720d746ae85014a1cf3344e18",
            "71802b86b93f40c59f6285c08837549f",
            "9b7d157f394d43189797cd5ea01904db",
            "7d99b9213d62463f90494cbf4b82724a",
            "a27e87e3a85049519cd2912711188de1",
            "b393dd98449f4ccdaea98fd60e3f60c5",
            "23d6ea6ef8714c5d88029b2c6bd2d3ab",
            "8e6e0ab69bb64faaaf9aad98d62fbcbe",
            "0fbd2cea6e104c0aacfffaa056aadbb2",
            "5be056183f35467d84be22c4cc4ac0f9",
            "3e8a1d75d941403ebcf824aa2ca85b8b",
            "9dcd4ae0b00c4b90971a428014b65843",
            "fbe02ccfd1e44f2b928dd01f70ab72f0",
            "0dc5e50a3a5149e8949329358bc0c774",
            "e31213fe34044504a35da7e1a3c7895a",
            "d19759d98af74b278c09eaed1a3bbbc8",
            "a62e7f7ac93842bd9ab1edfcaf7808f8",
            "9e23e29529464472b557e415732b42f8",
            "36e3e71ec55d4c3f87732f462913f1fb",
            "953bd96cf3a5483fbc563247953080e2",
            "7cc75c21953c4088a90c07140b96ce01",
            "ba1ab08d96844cacaf71edd889b25fb6",
            "aa3b51a4946244b1899033a2f66e2336",
            "1ca2d3f653a54740baa00122a99032ad",
            "37e2471baa694dc3bc375ae1dec94715",
            "c191818d9a3d4169b2f04640d28cd496",
            "2ec402dd112c478d9d9f17b4a4b6f982",
            "d4d70f7bdec74136b38dc3ed8bf568fe",
            "eca16ba21f144692a5d49f3e27db4098",
            "6d691ba42fb240a7b67d21ef8bf538ca",
            "c6d5820f9af145ef9db2bdba5bad166a",
            "1a90c69766c74b5da79ab336f4a27060",
            "ef5e7be0550e42539e2e597eb7c77d67",
            "d7f90b41e1964072b43ff26adb07b86c",
            "40382cdf9e3a4579a45d359fbbaa36ce",
            "f5f56b1359554745901c7d335ad00052",
            "6ff734b61e83423a956f8b7e34647010",
            "7aad97c5ea38440e8cbd5e06355150c3",
            "c8cc9a4b661544a4b0dcf454249f256a",
            "e6008157c5f241eba75eb2ad7217b1a7",
            "002780a964fd4278818b9ed6590b4164",
            "310768d7d8cf4654b7b345bcc9c17af8",
            "502d6f870e3d41528384340e8daf0f18",
            "bf132265009543a899d54d69c1787008",
            "c4c0edf6066944eaa4bcbeba46556ac7",
            "46195e18798441e4a4f03f3ad776da22",
            "0032f15a435e4202a3a94704db790707",
            "82ec472bfdcd4965b3630bea8079d2df",
            "ef30479ecda244ed8883d6e54182a210",
            "27eef1af3f604a388e66c00fafdbdce8",
            "a40c5c7fc2a6444fa9dea25d1970c926",
            "960b3df38662448fa424af289a0f1597",
            "5c0088dd1ade4cffa3fbc51b8490467b",
            "87687e1a6fa54332a6d7a3b31b0bf52b",
            "60e3cfe12ac14ecd8cdedc2ed8840950",
            "cf5ac303955d4d838f108679125515b6",
            "6fedc4ce862d46e38a69300f36680975",
            "bc5b0a720b4d427bbc8e08fbef5c412a",
            "329e20a67d2142a09bdada138044dea0",
            "584c67008c974238956fd1c2820c2e31",
            "b38f019c9de344fb9b63d419061051cb",
            "1057f8cec73a4e63a6bfa632f460a96e",
            "0f2050be06a143988093d44b401db978",
            "0cc4cb9965174a8f95200ea2733dc17b",
            "e56412a3abba4da59344b9095daad31b",
            "7d437f6e55ad4e818edb9b09007770d6",
            "0c052fe1880e4ac6b0a2a50b7cff8d40",
            "59d518468e054ef8adb20e115892827b",
            "d9e24e208aaa42e89d3dbade324b66f4",
            "b9bba4c064b04211930dd790672c79bf",
            "0eb9d9b2532c4fd6a7dced63a7ec43c9",
            "c79007224c9643b1a344f0728342070f",
            "25d71674406f40fba7e2ad9f4e74dce9",
            "2f4a988b59e4477d97ec31ffbd2e9e6b",
            "0243ebbe1be140838fe9814c0bbb7809",
            "1600008ac57a457882c5d3049e4b6d3b",
            "fdd3f7e8d79d4032ad76cd63a32279e9"
          ]
        },
        "id": "JbG50zx3UDtC",
        "outputId": "5abc69c9-2ee9-4001-ba5e-71d246902a72"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/930 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a97fa97720d746ae85014a1cf3344e18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/619 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9dcd4ae0b00c4b90971a428014b65843"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa3b51a4946244b1899033a2f66e2336"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7f90b41e1964072b43ff26adb07b86c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4c0edf6066944eaa4bcbeba46556ac7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.94k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf5ac303955d4d838f108679125515b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/357 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c052fe1880e4ac6b0a2a50b7cff8d40"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config.pad_token_id = config.eos_token_id\n",
        "tokenizer.pad_token = config.pad_token_id"
      ],
      "metadata": {
        "id": "_jNu0wqSUHLD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt = GPTJForCausalLM.from_pretrained(\"hivemind/gpt-j-6B-8bit\", low_cpu_mem_usage=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "17ae860e9f474cdbb17756fa8c5f17fb",
            "a79f948797c94c4c8d8018922e116558",
            "4b75975a20464e72877818d4908e1ebe",
            "397b93fdfc204be59ab5d9dce6c57fc3",
            "bb2b63cf77df44cf885ecd377628ced6",
            "542981591fa847829db3081483b41f5b",
            "eb407742d5ab4686b10558f32d1a7517",
            "cbd26656034a492fa011f66cab670b9a",
            "2c2111c4da6343bb9d562685eb4cb097",
            "981ec643c0c844c4b94eb94e4050f549",
            "955e735b4dc5485cb9dab29a55e42b78",
            "1552f07c39f04cfb94307b59e8c94e75",
            "2b5f7ccb08084ce98a52fab5b6d6b062",
            "9ab478afa3bf4d8f87a9ce2990c23f83",
            "5a15955e1aac475b9d11e518bbf2fa8d",
            "443f319f816a422ab89b079c004aeed1",
            "71cd5a62af8047b5a1a7d9f1f2ad85e2",
            "812617ac1eeb42deafac190f93d6df39",
            "b4b613632fbc4494ae6e842db1583742",
            "bc42cdf19df6400f8b468ef7ba2b14a2",
            "fd29a64fdb8d4be18273e7d8f3e3f9e5",
            "e5957e77f6fa4de2a4d308816354272e"
          ]
        },
        "id": "Bgs9xKkmULDa",
        "outputId": "8ddfefa1-fce9-4591-e470-57b0453b2b95"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17ae860e9f474cdbb17756fa8c5f17fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.75G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1552f07c39f04cfb94307b59e8c94e75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "lm_head Linear(in_features=4096, out_features=50400, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "f = open('train.json')\n",
        "\n",
        "data = json.load(f)\n",
        "array = {'Prompt':[]}\n",
        "for i in data:\n",
        "    if 'bot_reply' not in i:\n",
        "        array['Prompt'].append('prompt:' + i['prompt'] + ',commands:' + i['completion'])\n",
        "    else:\n",
        "        array['Prompt'].append('commands:' + i['commands'] + ',bot_reply:' + i['bot_reply'])\n",
        "\n",
        "dataset = pd.DataFrame.from_dict(array)\n",
        "dataset.to_csv('/content/train_data.csv', index=False)\n",
        "\n",
        "print(array['Prompt'])\n",
        "# print(len(array['Prompt']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rchC7vSyUw8A",
        "outputId": "a6d31306-0115-4c24-bae5-2fb4929e0936"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['prompt:Berikan daftar interface yang ada di Router A,commands:[Router A] show interfaces [eoc]', 'prompt:Saya membutuhkan informasi tentang semua interface di Router A,commands:[Router A] show interfaces [eoc]', 'prompt:Tunjukkan daftar semua interface yang tersedia di Router A,commands:[Router A] show interfaces [eoc]', 'prompt:Beri saya daftar semua antarmuka yang terhubung ke Router A,commands:[Router A] show interfaces [eoc]', 'prompt:Saya ingin melihat daftar interface di Router B,commands:[Router B] show interfaces [eoc]', 'prompt:Tolong berikan informasi tentang semua interface yang tersedia di Router B,commands:[Router B] show interfaces [eoc]', 'prompt:Tunjukkan saya daftar semua antarmuka di Router B,commands:[Router B] show interfaces [eoc]', 'prompt:Berikan daftar semua antarmuka yang terhubung ke Router C,commands:[Router C] show interfaces [eoc]', 'prompt:Saya memerlukan informasi tentang semua interface di Router C,commands:[Router C] show interfaces [eoc]', 'prompt:Tunjukkan semua interface yang tersedia di Router C,commands:[Router C] show interfaces [eoc]', 'prompt:Beri saya daftar semua antarmuka yang terhubung ke Router D,commands:[Router D] show interfaces [eoc]', 'prompt:Mohon informasi tentang semua interface di Router D,commands:[Router D] show interfaces [eoc]', 'prompt:Tolong tunjukkan daftar semua antarmuka di Router D,commands:[Router D] show interfaces [eoc]', 'prompt:Berikan daftar semua antarmuka yang terhubung ke Router internal,commands:[Router internal] show interfaces [eoc]', 'prompt:Saya membutuhkan informasi tentang semua interface di Router external,commands:[Router external] show interfaces [eoc]', 'prompt:Tolong tunjukkan daftar semua antarmuka di Router R1,commands:[Router R1] show interfaces [eoc]', 'prompt:Mohon berikan daftar semua antarmuka yang terhubung ke Router R2,commands:[Router R2] show interfaces [eoc]', 'prompt:Tolong berikan daftar interface untuk Router B Interface G0/0/0,commands:[Router B] show interface g0/0/0 [eoc]', 'prompt:Tunjukkan daftar interface yang tersedia di Router A Interface F0/0,commands:[Router A] show interface f0/0 [eoc]', 'prompt:Berikan daftar semua interface yang terhubung ke Router A Interface F0/1,commands:[Router A] show interface f0/1 [eoc]', 'prompt:Saya membutuhkan informasi tentang antarmuka F1/0 di Router A,commands:[Router A] show interface f1/0 [eoc]', 'prompt:Berikan daftar semua interface untuk Router B G0/1/1,commands:[Router B] show interface g0/1/1 [eoc]', 'prompt:Tolong tunjukkan daftar interface yang tersedia di Router B Interface G1/1/1,commands:[Router B] show interface g1/1/1 [eoc]', 'prompt:Beri saya daftar semua antarmuka yang tersedia di Router C F0/1,commands:[Router C] show interface f0/1 [eoc]', 'prompt:Saya membutuhkan informasi tentang interface G1/0/0 di Router R1,commands:[Router R1] show interface g1/0/0 [eoc]', 'prompt:Tunjukkan daftar semua interface yang terhubung ke Router R2 Interface G0/0/0,commands:[Router R2] show interface g0/0/0 [eoc]', 'prompt:Berikan daftar semua interface untuk Router R2 G0/0/1,commands:[Router R2] show interface g0/0/1 [eoc]', 'prompt:Tolong berikan daftar interface untuk Router R1 Interface F0/1,commands:[Router R1] show interface f0/1 [eoc]', 'prompt:Tolong ubah IP di Router C Interface X menjadi 192.168.1.1,commands:[Router C] configure terminal\\ninterface X\\nip address 192.168.1.1 255.255.255.0\\nend [eoc]', 'prompt:Ubah IP di Router A Interface G0/0/1 menjadi 10.0.0.1,commands:[Router A] configure terminal\\ninterface G0/0/1\\nip address 10.0.0.1 255.255.255.0\\nend [eoc]', 'prompt:Ubah IP di Router B Interface F0/1 menjadi 172.16.0.1,commands:[Router B] configure terminal\\ninterface F0/1\\nip address 172.16.0.1 255.255.255.0\\nend [eoc]', 'prompt:Tolong ubah IP di Internal Router Interface G1/0/0 menjadi 192.168.2.1,commands:[Internal Router] configure terminal\\ninterface G1/0/0\\nip address 192.168.2.1 255.255.255.0\\nend [eoc]', 'prompt:Saya butuh bantuan untuk mengubah IP di External Router Interface F1/0 menjadi 10.1.1.1,commands:[External Router] configure terminal\\ninterface F1/0\\nip address 10.1.1.1 255.255.255.0\\nend [eoc]', 'prompt:Mohon bantu untuk mengganti IP di R1 Interface G0/0/0 menjadi 192.168.3.1,commands:[Router R1] configure terminal\\ninterface G0/0/0\\nip address 192.168.3.1 255.255.255.0\\nend [eoc]', 'prompt:Mohon bantu untuk mengubah IP di Router D Interface F0/1 menjadi 172.16.10.1,commands:[Router D] configure terminal\\ninterface F0/1\\nip address 172.16.10.1 255.255.255.0\\nend [eoc]', 'prompt:Tolong ubah IP di Router E Interface G0/0 menjadi 192.168.5.1,commands:[Router E] configure terminal\\ninterface G0/0\\nip address 192.168.5.1 255.255.255.0\\nend [eoc]', 'prompt:Berikan bantuan untuk mengganti IP di Router F Interface F1/0 menjadi 10.1.2.1,commands:[Router F] configure terminal\\ninterface F1/0\\nip address 10.1.2.1 255.255.255.0\\nend [eoc]', 'prompt:Ubah IP di Router G Interface G0/0/1 menjadi 10.0.1.1,commands:[Router G] configure terminal\\ninterface G0/0/1\\nip address 10.0.1.1 255.255.255.0\\nend [eoc]', 'prompt:Mohon bantu untuk mengubah IP di R2 Interface F0/0 menjadi 192.168.4.1,commands:[Router R2] configure terminal\\ninterface F0/0\\nip address 192.168.4.1 255.255.255.0\\nend [eoc]', 'prompt:Tolong tambahkan kunci enkripsi ke Router D,commands:[Router D] configure terminal\\ncrypto key generate rsa\\nend [eoc]', 'prompt:Mohon tambahkan kunci enkripsi ke Router E,commands:[Router E] configure terminal\\ncrypto key generate rsa\\nend [eoc]', 'prompt:Tolong buat kunci enkripsi di Router F,commands:[Router F] configure terminal\\ncrypto key generate rsa\\nend [eoc]', 'prompt:Mohon tambahkan kunci enkripsi ke Router G,commands:[Router G] configure terminal\\ncrypto key generate rsa\\nend [eoc]', 'prompt:Tolong aktifkan enkripsi di Router H,commands:[Router H] configure terminal\\nservice password-encryption\\nend [eoc]', 'prompt:Mohon bantu untuk menambahkan kunci enkripsi di R1,commands:[Router R1] configure terminal\\ncrypto key generate rsa\\nend [eoc]', 'prompt:Saya ingin melihat daftar semua antarmuka di Router D,commands:[Router D] show interfaces [eoc]', 'prompt:Tunjukkan semua interface yang terhubung ke Router external,commands:[Router external] show interfaces [eoc]', 'prompt:Beri saya daftar semua antarmuka yang terhubung ke Router internal,commands:[Router internal] show interfaces [eoc]', 'prompt:Bagaimana cara mengkonfigurasi OSPF pada Router A?,commands:[Router A] router ospf 1\\nnetwork 10.0.0.0 0.255.255.255 area 0\\nend [eoc]', \"prompt:Berikan contoh penggunaan perintah 'ping' pada Router B,commands:[Router B] ping 10.0.0.1 [eoc]\", 'prompt:Bagaimana cara mengubah hostname pada Router C?,commands:[Router C] configure terminal\\nhostname NewHostName\\nend [eoc]', 'prompt:Saya ingin mengecek routing table pada Router A,commands:[Router A] show ip route [eoc]', 'prompt:Bagaimana cara mengkonfigurasi VLAN pada Switch A?,commands:[Switch A] vlan 10\\nname Sales\\nend [eoc]', 'prompt:Tolong buatkan ACL untuk memblokir akses ke situs web tertentu pada Router D,commands:[Router D] configure terminal\\naccess-list 101 deny tcp any host 192.168.1.2 eq 80\\naccess-list 101 permit ip any any\\ninterface gigabitEthernet 0/0\\nip access-group 101 in\\nend [eoc]', 'prompt:Bagaimana cara menampilkan port yang sedang aktif pada Switch B?,commands:[Switch B] show interface status [eoc]', 'prompt:Saya ingin mengkonfigurasi DHCP pada Router internal,commands:[Internal Router] configure terminal\\ndhcp pool InternalPool\\nnetwork 192.168.0.0 255.255.255.0\\ndefault-router 192.168.0.1\\nend [eoc]', 'prompt:Bagaimana cara menampilkan MAC address table pada Switch C?,commands:[Switch C] show mac-address-table [eoc]', 'prompt:Saya ingin mengkonfigurasi NAT pada Router external,commands:[Router external] configure terminal\\ninterface gigabitEthernet 0/0\\nip nat outside\\ninterface gigabitEthernet 0/1\\nip nat inside\\nip nat inside source list 1 interface gigabitEthernet 0/0 overload\\naccess-list 1 permit 192.168.0.0 0.0.255.255\\nend [eoc]', 'prompt:Bagaimana cara menampilkan log yang tersimpan pada Router R1?,commands:[Router R1] show logging [eoc]', 'prompt:Saya ingin memeriksa status koneksi pada Router R2,commands:[Router R2] show interfaces brief [eoc]', 'prompt:Bagaimana cara mengkonfigurasi trunking pada Switch D?,commands:[Switch D] interface gigabitEthernet 0/0\\nswitchport mode trunk\\nend [eoc]', 'prompt:Tolong buatkan static route pada Router internal untuk mengakses subnet 172.16.0.0/24 melalui Router A,commands:[Internal Router] ip route 172.16.0.0 255.255.255.0 10.0.0.2 [eoc]', 'prompt:Bagaimana cara menghapus VLAN yang tidak dibutuhkan pada Switch E?,commands:[Switch E] configure terminal\\nno vlan 10\\nend [eoc]', 'prompt:Saya ingin menampilkan informasi tentang status port pada Switch F,commands:[Switch F] show interface gigabitEthernet 0/1 [eoc]', 'prompt:Tunjukkan daftar konfigurasi yang ada di Router A,commands:[Router A] show running-config [eoc]', 'prompt:Beri saya daftar semua konfigurasi di Router A,commands:[Router A] show running-config [eoc]', 'prompt:Saya ingin melihat konfigurasi di Router B,commands:[Router B] show running-config [eoc]', 'prompt:Tolong berikan daftar semua konfigurasi di Router B,commands:[Router B] show running-config [eoc]', 'prompt:Berikan daftar semua konfigurasi di Router C,commands:[Router C] show running-config [eoc]', 'prompt:Saya memerlukan informasi tentang konfigurasi di Router C,commands:[Router C] show running-config [eoc]', 'prompt:Tunjukkan semua konfigurasi di Router D,commands:[Router D] show running-config [eoc]', 'prompt:Berikan daftar semua konfigurasi di Router internal,commands:[Router internal] show running-config [eoc]', 'prompt:Saya membutuhkan informasi tentang semua konfigurasi di Router external,commands:[Router external] show running-config [eoc]', 'prompt:Tolong tunjukkan daftar semua konfigurasi di Router R1,commands:[Router R1] show running-config [eoc]', 'prompt:Mohon berikan daftar semua konfigurasi di Router R2,commands:[Router R2] show running-config [eoc]', 'prompt:Tunjukkan daftar konfigurasi untuk Router B Interface G0/0/0,commands:[Router B] show running-config interface g0/0/0 [eoc]', 'prompt:Berikan konfigurasi untuk Router A Interface F0/0,commands:[Router A] show running-config interface f0/0 [eoc]', 'prompt:Saya membutuhkan informasi tentang konfigurasi di Router A Interface F0/1,commands:[Router A] show running-config interface f0/1 [eoc]', 'prompt:Tolong berikan konfigurasi untuk interface F1/0 di Router A,commands:[Router A] show running-config interface f1/0 [eoc]', 'prompt:Berikan konfigurasi untuk Router B G0/1/1,commands:[Router B] show running-config interface g0/1/1 [eoc]', 'prompt:Tunjukkan daftar konfigurasi yang terhubung ke Router B Interface G1/1/1,commands:[Router B] show running-config interface g1/1/1 [eoc]', 'prompt:Beri saya konfigurasi semua antarmuka yang tersedia di Router C F0/1,commands:[Router C] show running-config interface f0/1 [eoc]', 'prompt:Saya membutuhkan informasi tentang konfigurasi di interface G1/0/0 di Router R1,commands:[Router R1] show running-config interface g1/0/0 [eoc]', 'prompt:Tunjukkan daftar konfigurasi semua interface yang terhubung ke Router R2 Interface G0/0/0,commands:[Router R2] show running-config interface g0/0/0 [eoc]', 'prompt:Berikan konfigurasi untuk semua interface pada Router R2 G0/0/1,commands:[Router R2] show running-config interface g0/0/1 [eoc]', 'prompt:Beri saya daftar konfigurasi di Router D yang terkait dengan VLAN 10,commands:[Router D] show running-config | include vlan 10 [eoc]', 'prompt:Tunjukkan konfigurasi yang berhubungan dengan OSPF di Router A,commands:[Router A] show running-config | include ospf [eoc]', 'prompt:Beri saya daftar semua konfigurasi yang terkait dengan NAT di Router B,commands:[Router B] show running-config | include nat [eoc]', 'prompt:Saya ingin melihat daftar konfigurasi yang terkait dengan DHCP di Router C,commands:[Router C] show running-config | include dhcp [eoc]', 'prompt:Tolong tunjukkan daftar semua konfigurasi yang terkait dengan firewall di Router internal,commands:[Router internal] show running-config | include firewall [eoc]', 'prompt:Berikan konfigurasi untuk interface G0/0 di Router external,commands:[Router external] show running-config interface g0/0 [eoc]', 'prompt:Saya memerlukan informasi tentang konfigurasi VRF di Router R1,commands:[Router R1] show running-config | include vrf [eoc]', 'prompt:Tunjukkan daftar konfigurasi terkait dengan access-list di Router R2,commands:[Router R2] show running-config | include access-list [eoc]', 'prompt:Berikan daftar semua konfigurasi OSPF yang terkait dengan area 0 di Router A,commands:[Router A] show running-config | include ospf.*area 0 [eoc]', 'prompt:Saya ingin melihat konfigurasi NAT yang terkait dengan subnet 192.168.1.0/24 di Router B,commands:[Router B] show running-config | include nat.*192.168.1.0/24 [eoc]', 'prompt:Tolong berikan daftar konfigurasi BGP di Router C,commands:[Router C] show running-config | include bgp [eoc]', 'prompt:Saya membutuhkan informasi tentang konfigurasi QoS di Router internal,commands:[Router internal] show running-config | include qos [eoc]', 'prompt:Tunjukkan daftar konfigurasi yang terkait dengan MPLS di Router external,commands:[Router external] show running-config | include mpls [eoc]', 'prompt:Berikan konfigurasi untuk interface F0/1 di Router R1,commands:[Router R1] show running-config interface f0/1 [eoc]', 'prompt:Saya memerlukan informasi tentang konfigurasi VPC di Router R2,commands:[Router R2] show running-config | include vpc [eoc]', 'prompt:Tolong tunjukkan daftar konfigurasi yang terkait dengan IPsec di Router A,commands:[Router A] show running-config | include ipsec [eoc]', 'prompt:Tolong atur VLAN 10 pada Switch A dan hubungkan ke port GigabitEthernet1/0/5,commands:[Switch A] configure terminal\\nvlan 10\\nname VLAN10\\ninterface GigabitEthernet1/0/5\\nswitchport mode access\\nswitchport access vlan 10\\nend [eoc]', 'prompt:Tambahkan static route pada Router D untuk subnet 192.168.10.0/24 melalui Router B dengan metric 10,commands:[Router D] configure terminal\\nip route 192.168.10.0 255.255.255.0 Router B 10\\nend [eoc]', \"prompt:Tolong tambahkan user baru bernama 'john' dengan password 'password123' pada server MySQL,commands:CREATE USER 'john'@'localhost' IDENTIFIED BY 'password123';\\nGRANT ALL PRIVILEGES ON * . * TO 'john'@'localhost';\\nFLUSH PRIVILEGES; [eoc]\", 'prompt:Tolong tambahkan firewall rule pada server web untuk memblokir akses dari IP address 192.168.1.100,commands:sudo ufw deny from 192.168.1.100 [eoc]', 'prompt:Tolong buat konfigurasi NAT pada Router A untuk mengakses jaringan internal (192.168.1.0/24) dari internet,commands:[Router A] configure terminal\\ninterface GigabitEthernet0/0/1\\nip nat outside\\nexit\\ninterface GigabitEthernet0/0/0\\nip nat inside\\nexit\\nip nat inside source list 1 interface GigabitEthernet0/0/1 overload\\naccess-list 1 permit 192.168.1.0 0.0.0.255\\nend [eoc]', 'prompt:Buat route static menuju network 192.168.1.0 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0 di Router A,commands:[Router A] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Ciptakan skrip konfigurasi yang akan menetapkan route statis pada Router A untuk mengarahkan lalu lintas ke jaringan 192.168.1.0 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0,commands:[Router A] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Konfigurasikan routing statis di Router A untuk mengarahkan lalu lintas ke jaringan 192.168.1.0 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0,commands:[Router A] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Ciptakan konfigurasi perutean yang tepat pada Router A untuk memungkinkan lalu lintas menuju jaringan 192.168.1.0 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0,commands:[Router A] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Tulis skrip perutean yang diperlukan untuk mengarahkan semua paket menuju jaringan 192.168.1.0 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0 di Router A,commands:[Router A] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A dan perkenalkan network 192.168.2.0, 192.168.3.0,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Lakukan konfigurasi pada Router A untuk mengaktifkan protokol RIP versi 2 dan perkenalkan network 192.168.2.0 dan 192.168.3.0 ke dalam perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A dan pastikan network 192.168.2.0 dan 192.168.3.0 dikenali oleh perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Lakukan langkah-langkah untuk mengaktifkan protokol RIP versi 2 pada Router A dan pastikan network 192.168.2.0 dan 192.168.3.0 dapat diakses melalui perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A sekarang juga dan segera perkenalkan network 192.168.2.0 dan 192.168.3.0 ke dalam tabel perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 dengan IP address 192.168.0.1 subnet 255.255.255.0 pada interface g0/0 di Router A,commands:[Router A] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router A dan berikan IP address 192.168.0.1 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 11 pada interface g0/0 di Router A dengan IP address 192.168.0.1 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router A dan tetapkan IP address 192.168.0.1 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router A dan pastikan menggunakan IP address 192.168.0.1 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 dengan IP address 192.168.1.1 subnet 255.255.255.0 pada interface g0/0 di Router A,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router A dan berikan IP address 192.168.1.1 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 22 pada interface g0/0 di Router A dengan IP address 192.168.1.1 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router A dan tetapkan IP address 192.168.1.1 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router A dan pastikan menggunakan IP address 192.168.1.1 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 dengan IP address 192.168.2.1 subnet 255.255.255.0 pada interface g0/0 di Router A,commands:[Router A] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g0/0 di Router A dan berikan IP address 192.168.2.1 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 33 pada interface g0/0 di Router A dengan IP address 192.168.2.1 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g0/0 di Router A dan tetapkan IP address 192.168.2.1 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g0/0 di Router A dan pastikan menggunakan IP address 192.168.2.1 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Buat route static menuju network 192.168.0.1 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0 di Router B,commands:[Router B] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Ciptakan skrip konfigurasi yang akan menetapkan route statis pada Router B untuk mengarahkan lalu lintas ke jaringan 192.168.0.1 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0,commands:[Router B] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Konfigurasikan routing statis di Router B untuk mengarahkan lalu lintas ke jaringan 192.168.0.1 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0,commands:[Router B] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Ciptakan konfigurasi perutean yang tepat pada Router B untuk memungkinkan lalu lintas menuju jaringan 192.168.0.1 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0,commands:[Router B] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Tulis skrip perutean yang diperlukan untuk mengarahkan semua paket menuju jaringan 192.168.0.1 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0 di Router B,commands:[Router B] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router B dan perkenalkan network 192.168.1.0, 192.168.2.0,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Lakukan konfigurasi pada Router B untuk mengaktifkan protokol RIP versi 2 dan perkenalkan network 192.168.1.0 dan 192.168.2.0 ke dalam perutean,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router B dan pastikan network 192.168.1.0 dan 192.168.2.0 dikenali oleh perutean,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Lakukan langkah-langkah untuk mengaktifkan protokol RIP versi 2 pada Router B dan pastikan network 192.168.1.0 dan 192.168.2.0 dapat diakses melalui perutean,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router B sekarang juga dan segera perkenalkan network 192.168.1.0 dan 192.168.2.0 ke dalam tabel perutean,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 dengan IP address 192.168.0.2 subnet 255.255.255.0 pada interface g0/0 di Router B,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.2 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 11 pada interface g0/0 di Router B dengan IP address 192.168.0.2 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router B dan berikan IP address 192.168.0.2 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router B dan tetapkan IP address 192.168.0.2 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router B dan pastikan menggunakan IP address 192.168.0.2 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 dengan IP address 192.168.2.1 subnet 255.255.255.0 pada interface g0/0 di Router B,commands:[Router B] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router B dan berikan IP address 192.168.2.1 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 22 pada interface g0/0 di Router B dengan IP address 192.168.2.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router B dan tetapkan IP address 192.168.2.1 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router B dan pastikan menggunakan IP address 192.168.2.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Buat route static menuju network 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/0 di Router A,commands:[Router A] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc]', 'prompt:Ciptakan skrip konfigurasi yang akan menetapkan route statis pada Router A untuk mengarahkan lalu lintas ke jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/0,commands:[Router A] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc]', 'prompt:Konfigurasikan routing statis di Router A untuk mengarahkan lalu lintas ke jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/0,commands:[Router A] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc]', 'prompt:Ciptakan konfigurasi perutean yang tepat pada Router A untuk memungkinkan lalu lintas menuju jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/0,commands:[Router A] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc]', 'prompt:Tulis skrip perutean yang diperlukan untuk mengarahkan semua paket menuju jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/0 di Router A,commands:[Router A] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A dan perkenalkan network 192.168.0.1, 192.168.2.0,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Lakukan konfigurasi pada Router A untuk mengaktifkan protokol RIP versi 2 dan perkenalkan network 192.168.0.1 dan 192.168.2.0 ke dalam perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A dan pastikan network 192.168.0.1 dan 192.168.2.0 dikenali oleh perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Lakukan langkah-langkah untuk mengaktifkan protokol RIP versi 2 pada Router A dan pastikan network 192.168.0.1 dan 192.168.2.0 dapat diakses melalui perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A sekarang juga dan segera perkenalkan network 192.168.0.1 dan 192.168.2.0 ke dalam tabel perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Buat route static menuju network 192.168.2.0 dengan subnet mask 255.255.255.0 melalui interface g/1/1/0 di Router A,commands:[Router A] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc]', 'prompt:Ciptakan skrip konfigurasi yang akan menetapkan route statis pada Router A untuk mengarahkan lalu lintas ke jaringan 192.168.2.0 dengan subnet mask 255.255.255.0 melalui interface g/1/1/0,commands:[Router A] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc]', 'prompt:Konfigurasikan routing statis di Router A untuk mengarahkan lalu lintas ke jaringan 192.168.2.0 dengan subnet mask 255.255.255.0 melalui interface g/1/1/0,commands:[Router A] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc]', 'prompt:Ciptakan konfigurasi perutean yang tepat pada Router A untuk memungkinkan lalu lintas menuju jaringan 192.168.2.0 dengan subnet mask 255.255.255.0 melalui interface g/1/1/0,commands:[Router A] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc]', 'prompt:Tulis skrip perutean yang diperlukan untuk mengarahkan semua paket menuju jaringan 192.168.2.0 dengan subnet mask 255.255.255.0 melalui interface g/1/1/0 di Router A,commands:[Router A] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A dan perkenalkan network 192.168.0.1, 192.168.3.0,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Aktifkan versi 2 dari protokol RIP di Router A dan tambahkan jaringan 192.168.0.1 dan 192.168.3.0 ke dalam konfigurasi.,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Menambahkan  jaringan dengan alamat IP 192.168.0.1 dan 192.168.3.0 ke dalam konfigurasi lalu aktifkan protokol RIP versi 2 pada Router A,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Tambahkan jaringan 192.168.0.1 dan 192.168.3.0 ke dalam konfigurasi, kemudian aktifkan protokol RIP versi 2 pada Router A,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Lakukan langkah-langkah untuk mengaktifkan protokol RIP versi 2 pada Router A dan pastikan network 192.168.0.1 dan 192.168.3.0 dapat diakses melalui perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router B dan perkenalkan network 192.168.1.0, 192.168.3.0,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Pada Router A, tambahkan network 192.168.0.1 serta 192.168.3.0 dan aktifkan protokol RIP versi 2,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Tambahkan jaringan 192.168.0.1 dan 192.168.3.0 ke dalam konfigurasi Router A, serta aktifkan protokol RIP versi 2.,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A, serta pastikan jaringan 192.168.0.1 serta 192.168.3.0 sudah dikenali pada konfigurasi perutean,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Lakukan pengaktifan protokol RIP versi 2 pada Router A dan pastikan bahwa jaringan 192.168.0.1 dan 192.168.3.0 telah terdaftar dalam konfigurasi routing,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 dengan IP address 192.168.0.1 subnet 255.255.255.0 pada interface g0/0 di Router B,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Mengaktifkan VLAN 33 pada antarmuka g0/0 di Router B dengan alamat IP 192.168.0.1 dan subnet 255.255.255.0.,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 33 pada interface g0/0 di Router B dengan IP address 192.168.0.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Konfigurasikan VLAN 33 pada antarmuka g0/0 di Router B dengan alamat IP 192.168.0.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan konfigurasi VLAN 33 pada interface g0/0 di Router B dengan alamat IP 192.168.0.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Buat route static menuju network 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/1 di Router B,commands:[Router B] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/1\\n end [eoc]', 'prompt:Lakukan konfigurasi yang menetapkan route statis pada Router B untuk mengarahkan lalu lintas ke jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/1,commands:[Router B] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/1\\n end [eoc]', 'prompt:Lakukan pengaturan konfigurasi pada Router B untuk mengonfigurasi rute statis yang mengarahkan lalu lintas ke jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui antarmuka g/1/0/1.,commands:[Router B] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/1\\n end [eoc]', 'prompt:Tulis skrip perutean yang diperlukan untuk mengarahkan semua paket menuju jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/1 di Router B,commands:[Router B] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/1\\n end [eoc]', 'prompt:Tuliskan skrip rute yang diperlukan untuk mengalihkan semua paket ke jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui antarmuka g/1/0/1 di Router B.,commands:[Router B] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/1\\n end [eoc]', 'prompt:Aktifkan VLAN 33 dengan IP address 192.168.3.0 subnet 255.255.255.0 pada interface g1/0 di Router B,commands:[Router B] configure terminal\\nint g1/0.33\\nencapsulation dot1q 33\\nip address 192.168.3.0 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 33 pada antarmuka g1/0 di Router B dengan IP address 192.168.3.0 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g1/0.33\\nencapsulation dot1q 33\\nip address 192.168.3.0 255.255.255.0\\n end [eoc]', 'prompt:Konfigurasikan VLAN 33 pada interface Router B g1/0 dengan alamat IP 192.168.3.0 dan subnet mask 255.255.255.0.,commands:[Router B] configure terminal\\nint g1/0.33\\nencapsulation dot1q 33\\nip address 192.168.3.0 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan konfigurasi VLAN 33 pada interface g1/0 di Router B dengan alamat IP 192.168.3.0 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g1/0.33\\nencapsulation dot1q 33\\nip address 192.168.3.0 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g1/0 di Router B dan pastikan menggunakan IP address 192.168.3.0 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g1/0.33\\nencapsulation dot1q 33\\nip address 192.168.3.0 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 dengan IP address 192.168.2.2 subnet 255.255.255.0 pada interface g0/1 di Router A,commands:[Router A] configure terminal\\nint g0/1.11\\nencapsulation dot1q 11\\nip address 192.168.2.2 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 11 pada interface g0/1 di Router A dengan IP address 192.168.2.2 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/1.11\\nencapsulation dot1q 11\\nip address 192.168.2.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/1 di Router A dan berikan IP address 192.168.2.2 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/1.11\\nencapsulation dot1q 11\\nip address 192.168.2.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/1 di Router A dan tetapkan IP address 192.168.2.2 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/1.11\\nencapsulation dot1q 11\\nip address 192.168.2.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/1 di Router A dan pastikan menggunakan IP address 192.168.2.2 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/1.11\\nencapsulation dot1q 11\\nip address 192.168.2.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 dengan IP address 192.168.1.1 subnet 255.255.255.0 pada interface g0/0 di Router B,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 33 pada antarmuka g0/0 di Router B dengan IP address 192.168.1.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Konfigurasikan VLAN 33 pada interface Router B g0/0 dengan alamat IP 192.168.1.1 dan subnet mask 255.255.255.0.,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan konfigurasi VLAN 33 pada interface g0/0 di Router B dengan alamat IP 192.168.1.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g0/0 di Router B dan pastikan menggunakan IP address 192.168.1.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 dengan IP address 192.168.0.3 subnet 255.255.255.0 pada interface g0/1 di Router B,commands:[Router B] configure terminal\\nint g0/1.22\\nencapsulation dot1q 22\\nip address 192.168.0.3 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 22 pada interface g0/1 di Router B dengan IP address 192.168.0.3 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/1.22\\nencapsulation dot1q 22\\nip address 192.168.0.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/1 di Router B dan berikan IP address 192.168.0.3 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/1.22\\nencapsulation dot1q 22\\nip address 192.168.0.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/1 di Router B dan tetapkan IP address 192.168.0.3 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/1.22\\nencapsulation dot1q 22\\nip address 192.168.0.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/1 di Router B dan pastikan menggunakan IP address 192.168.0.3 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/1.22\\nencapsulation dot1q 22\\nip address 192.168.0.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 dengan IP address 192.168.2.3 subnet 255.255.255.0 pada interface g0/0 di Router A,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 2 pada interface g0/0 di Router A dan berikan IP address 192.168.2.3 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.3 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 22 pada interface g0/0 di Router A dengan IP address 192.168.2.3 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router A dan tetapkan IP address 192.168.2.3 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router A dan pastikan menggunakan IP address 192.168.2.3 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 dengan IP address 192.168.2.4 subnet 255.255.255.0 pada interface g1/1 di Router A,commands:[Router A] configure terminal\\nint g1/1.22\\nencapsulation dot1q 22\\nip address 192.168.2.4 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 22 pada interface g1/1 di Router A dengan IP address 192.168.2.4 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.22\\nencapsulation dot1q 22\\nip address 192.168.2.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g1/1 di Router A dan berikan IP address 192.168.2.4 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.22\\nencapsulation dot1q 22\\nip address 192.168.2.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g1/1 di Router A dan tetapkan IP address 192.168.2.4 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.22\\nencapsulation dot1q 22\\nip address 192.168.2.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g1/1 di Router A dan pastikan menggunakan IP address 192.168.2.4 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.22\\nencapsulation dot1q 22\\nip address 192.168.2.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 dengan IP address 192.168.0.4 subnet 255.255.255.0 pada interface g0/0 di Router B,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g0/0 di Router B dan berikan IP address 192.168.0.4 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.4 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 33 pada interface g0/0 di Router B dengan IP address 192.168.0.4 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g0/0 di Router B dan tetapkan IP address 192.168.0.4 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g0/0 di Router B dan pastikan menggunakan IP address 192.168.0.4 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 dengan IP address 192.168.1.2 subnet 255.255.255.0 pada interface g0/0 di Router B,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.1.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router B dan berikan IP address 192.168.1.2 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.1.2 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 11 pada interface g0/0 di Router B dengan IP address 192.168.1.2 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.1.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router B dan tetapkan IP address 192.168.1.2 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.1.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router B dan pastikan menggunakan IP address 192.168.1.2 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.1.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 dengan IP address 192.168.1.4 subnet 255.255.255.0 pada interface g1/1 di Router A,commands:[Router A] configure terminal\\nint g1/1.11\\nencapsulation dot1q 11\\nip address 192.168.1.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g1/1 di Router A dan berikan IP address 192.168.1.4 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.11\\nencapsulation dot1q 11\\nip address 192.168.1.4 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 11 pada interface g1/1 di Router A dengan IP address 192.168.1.4 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.11\\nencapsulation dot1q 11\\nip address 192.168.1.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g1/1 di Router A dan tetapkan IP address 192.168.1.4 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.11\\nencapsulation dot1q 11\\nip address 192.168.1.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g1/1 di Router A dan pastikan menggunakan IP address 192.168.1.4 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.11\\nencapsulation dot1q 11\\nip address 192.168.1.4 255.255.255.0\\n end [eoc]', 'commands:[Router Z] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc],bot_reply:Untuk membuat rute pada Router Z melalui interface g/0/0/0 menuju jaringan lokal dengan IP 192.168.1.0, subnet mask 255.255.255.0 kita perlu menyatakan pemanggilan konfigurasi Router Z terlebih dahulu dengan menggunakan perintah\\n[Router Z] configure terminal\\nLalu dengan perintah ip route tambahkan alamat IP tujuan, subnet mask, dan interface. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router Z] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\nend [eoc]', 'commands:[Router I] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc],bot_reply:Untuk mengkonfigurasi rute pada Router I untuk jaringan lokal dengan alamat IP 192.168.1.0 dan subnet mask 255.255.255.0, Anda harus mulai dengan mengakses mode konfigurasi menggunakan perintah:\\n[Router I] configure terminal\\nSelanjutnya, tambahkan alamat IP tujuan, subnet mask, dan antarmuka menggunakan perintah `ip route`. Urutan perintah diakhiri dengan yang berikut:\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\nend [eoc]\\nAnda dapat menjalankan serangkaian perintah seperti yang disebutkan di atas.', 'commands:[Router X] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc],bot_reply:Untuk mengatur rute pada Router X untuk jaringan lokal dengan alamat IP 192.168.1.0 dan subnet mask 255.255.255.0, langkah pertama adalah masuk ke mode konfigurasi menggunakan perintah berikut:\\n[Router X] configure terminal\\nSelanjutnya, gunakan perintah `ip route` untuk menambahkan alamat IP tujuan, subnet mask, dan antarmuka. Akhir dari urutan perintah adalah sebagai berikut:\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\nend [eoc]Anda dapat melaksanakan rangkaian perintah sebagaimana dijelaskan di atas.', 'commands:[Router C] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router C dan pendaftaran alamat IP 192.168.2.0 dan 192.168.3.0 pada perutean, perlu dinyatakan ppemanggilan konfigurasi Router C terlebih dahulu dengan perintah\\n[Router C] configure terminal\\nLalu tambahkan perintah router rip dan version 2 untuk menandakan akan digunakan protokol RIP versi 2\\nrouter rip\\nversion 2\\nSetelah itu cantumkan alamat IP asal dan alamat IP tujuan dengan menggunakan perintah network. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router C] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\nend [eoc]', 'commands:[Router K] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router K dan mendaftarkan alamat IP 192.168.2.0 dan 192.168.3.0 pada perutean, langkah awal adalah memasuki mode konfigurasi pada Router K dengan perintah:\\n[Router K] configure terminal\\nSetelah itu, gunakan perintah `router rip` dan `version 2` untuk menandakan bahwa Anda akan menggunakan protokol RIP versi 2:\\nrouter rip\\nversion 2\\nSelanjutnya, tambahkan alamat IP sumber dan tujuan dengan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Rangkaian perintah dapat dijalankan sebagai berikut:\\n[Router K] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\nend [eoc]\\nAnda dapat melaksanakan rangkaian perintah seperti di atas.', 'commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router A dan memasukkan alamat IP 192.168.2.0 dan 192.168.3.0 pada tabel routing, langkah awal adalah mengakses mode konfigurasi pada Router A menggunakan perintah berikut:\\n[Router A] configure terminal\\nAfterward, utilize the `router rip` and `version 2` commands to specify the use of RIP protocol version 2:\\nrouter rip\\nversion 2\\nSelanjutnya, gabungkan alamat IP sumber dan tujuan menggunakan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Perintah-perintah tersebut dapat dijalankan sebagai berikut:\\n[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\nend [eoc]\\nAnda dapat menerapkan urutan perintah seperti yang ditunjukkan di atas.', 'commands:[Router K] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc],bot_reply:Untuk mengaktifkan VLAN 11 pada Router K dengan interface g0/0, alamat IP 192.168.0.1, dan subnet mask 255.255.255.0 kita perlu menyatakan pemanggilan konfigurasi Router K terlebih dahulu dengan menggunakan perintah\\n[Router K] configure terminal\\nLalu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask dapat digunakan perintah int, encapsulation, dan ip address\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router K] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\nend [eoc]', 'commands:[Router G] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc],bot_reply:Untuk mengaktifkan VLAN 11 pada Router G dengan alamat IP 192.168.0.1, interface g0/0, dan subnet mask 255.255.255.0  perlu dilakukan pemanggilan konfigurasi Router G terlebih dahulu dengan menggunakan perintah\\n[Router G] configure terminal\\nSetelah itu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask dapat digunakan perintah int, encapsulation, dan ip address\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah adalah sebagai berikut:\\n[Router G] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\nend [eoc]', 'commands:[Router A] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc],bot_reply:Anda dapat mengaktifkan VLAN 11 pada Router A dengan alamat IP 192.168.0.1, interface g0/0, dan subnet mask 255.255.255.0 dengan langkah pertama melakukan pemanggilan konfigurasi Router A terlebih dahulu dengan menggunakan perintah\\n[Router A] configure terminal\\nLalu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask gunakan perintah int, encapsulation, dan ip address\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Perintah lengkapnya, yaitu:\\n[Router A] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\nend [eoc]', 'commands:[Router G] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc],bot_reply:Untuk mengaktifkan VLAN 22 pada Router G dengan alamat IP 192.168.1.1, interface g0/0, dan subnet mask 255.255.255.0  perlu dilakukan pemanggilan konfigurasi Router G terlebih dahulu dengan menggunakan perintah\\n[Router G] configure terminal\\nSetelah itu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask dapat digunakan perintah int, encapsulation, dan ip address\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah adalah sebagai berikut:\\n[Router G] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\nend [eoc]', 'commands:[Router O] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc],bot_reply:Untuk mengaktifkan VLAN 22 pada Router O dengan interface g0/0, alamat IP 192.168.2.1, dan subnet mask 255.255.255.0 kita perlu menyatakan pemanggilan konfigurasi Router O terlebih dahulu dengan menggunakan perintah\\n[Router O] configure terminal\\nLalu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask dapat digunakan perintah int, encapsulation, dan ip address\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router O] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nend [eoc]', 'commands:[Router I] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc],bot_reply:Anda dapat mengaktifkan VLAN 22 pada Router I dengan alamat IP 192.168.1.1, interface g0/0, dan subnet mask 255.255.255.0 dengan langkah pertama melakukan pemanggilan konfigurasi Router I terlebih dahulu dengan menggunakan perintah\\n[Router I] configure terminal\\nLalu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask gunakan perintah int, encapsulation, dan ip address\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Perintah lengkapnya, yaitu:\\n[Router I] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\nend [eoc]', 'commands:[Router A] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc],bot_reply:Untuk mengaktifkan VLAN 33 pada Router A dengan alamat IP 192.168.2.1, interface g0/0, dan subnet mask 255.255.255.0  perlu dilakukan pemanggilan konfigurasi Router A terlebih dahulu dengan menggunakan perintah\\n[Router A] configure terminal\\nSetelah itu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask dapat digunakan perintah int, encapsulation, dan ip address\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah adalah sebagai berikut:\\n[Router A] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nend [eoc]', 'commands:[Router I] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc],bot_reply:Untuk mengaktifkan VLAN 33 pada Router I dengan interface g0/0, alamat IP 192.168.2.1, dan subnet mask 255.255.255.0 kita perlu menyatakan pemanggilan konfigurasi Router I terlebih dahulu dengan menggunakan perintah\\n[Router I] configure terminal\\nLalu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask dapat digunakan perintah int, encapsulation, dan ip address\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router I] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nend [eoc]', 'commands:[Router Z] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc],bot_reply:Anda dapat mengaktifkan VLAN 33 pada Router Z dengan alamat IP 192.168.2.1, interface g0/0, dan subnet mask 255.255.255.0 dengan langkah pertama melakukan pemanggilan konfigurasi Router Z terlebih dahulu dengan menggunakan perintah\\n[Router Z] configure terminal\\nLalu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask gunakan perintah int, encapsulation, dan ip address\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Perintah lengkapnya, yaitu:\\n[Router Z] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nend [eoc]', 'commands:[Router K] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc],bot_reply:Untuk membuat rute pada Router K melalui interface g/0/0/0 menuju jaringan lokal dengan IP 192.168.0.1, subnet mask 255.255.255.0 kita perlu menyatakan pemanggilan konfigurasi Router K terlebih dahulu dengan menggunakan perintah\\n[Router K] configure terminal\\nLalu dengan perintah ip route tambahkan alamat IP tujuan, subnet mask, dan interface. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router K] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\nend [eoc]', 'commands:[Router K] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc],bot_reply:Untuk mengkonfigurasi rute pada Router K untuk jaringan lokal dengan alamat IP 192.168.0.1 dan subnet mask 255.255.255.0, Anda harus mulai dengan mengakses mode konfigurasi menggunakan perintah:\\n[Router K] configure terminal\\nSelanjutnya, tambahkan alamat IP tujuan, subnet mask, dan antarmuka menggunakan perintah `ip route`. Urutan perintah diakhiri dengan yang berikut:\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\nend [eoc]\\nAnda dapat menjalankan serangkaian perintah seperti yang disebutkan di atas.', 'commands:[Router C] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc],bot_reply:Untuk mengatur rute pada Router C untuk jaringan lokal dengan alamat IP 192.168.0.1 dan subnet mask 255.255.255.0, langkah pertama adalah masuk ke mode konfigurasi menggunakan perintah berikut:\\n[Router C] configure terminal\\nSelanjutnya, gunakan perintah `ip route` untuk menambahkan alamat IP tujuan, subnet mask, dan antarmuka. Akhir dari urutan perintah adalah sebagai berikut:\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\nend [eoc]Anda dapat melaksanakan rangkaian perintah sebagaimana dijelaskan di atas.', 'commands:[Router X] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router X dan pendaftaran alamat IP 192.168.1.0 dan 192.168.2.0 pada perutean, perlu dinyatakan ppemanggilan konfigurasi Router X terlebih dahulu dengan perintah\\n[Router X] configure terminal\\nLalu tambahkan perintah router rip dan version 2 untuk menandakan akan digunakan protokol RIP versi 2\\nrouter rip\\nversion 2\\nSetelah itu cantumkan alamat IP asal dan alamat IP tujuan dengan menggunakan perintah network. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router X] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\nend [eoc]', 'commands:[Router Y] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router Y dan mendaftarkan alamat IP 192.168.1.0 dan 192.168.2.0 pada perutean, langkah awal adalah memasuki mode konfigurasi pada Router Y dengan perintah:\\n[Router Y] configure terminal\\nSetelah itu, gunakan perintah `router rip` dan `version 2` untuk menandakan bahwa Anda akan menggunakan protokol RIP versi 2:\\nrouter rip\\nversion 2\\nSelanjutnya, tambahkan alamat IP sumber dan tujuan dengan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Rangkaian perintah dapat dijalankan sebagai berikut:\\n[Router Y] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\nend [eoc]\\nAnda dapat melaksanakan rangkaian perintah seperti di atas.', 'commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router B dan memasukkan alamat IP 192.168.1.0 dan 192.168.2.0 pada tabel routing, langkah awal adalah mengakses mode konfigurasi pada Router B menggunakan perintah berikut:\\n[Router B] configure terminal\\nAfterward, utilize the `router rip` and `version 2` commands to specify the use of RIP protocol version 2:\\nrouter rip\\nversion 2\\nSelanjutnya, gabungkan alamat IP sumber dan tujuan menggunakan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Perintah-perintah tersebut dapat dijalankan sebagai berikut:\\n[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\nend [eoc]\\nAnda dapat menerapkan urutan perintah seperti yang ditunjukkan di atas.', 'commands:[Router B] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc],bot_reply:Untuk membuat rute pada Router B melalui interface g/1/0/0 menuju jaringan lokal dengan IP 192.168.3.0, subnet mask 255.255.255.0 kita perlu menyatakan pemanggilan konfigurasi Router B terlebih dahulu dengan menggunakan perintah\\n[Router B] configure terminal\\nLalu dengan perintah ip route tambahkan alamat IP tujuan, subnet mask, dan interface. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router B] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\nend [eoc]', 'commands:[Router Y] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc],bot_reply:Untuk mengkonfigurasi rute pada Router Y untuk jaringan lokal dengan alamat IP 192.168.3.0 dan subnet mask 255.255.255.0, Anda harus mulai dengan mengakses mode konfigurasi menggunakan perintah:\\n[Router Y] configure terminal\\nSelanjutnya, tambahkan alamat IP tujuan, subnet mask, dan antarmuka menggunakan perintah `ip route`. Urutan perintah diakhiri dengan yang berikut:\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\nend [eoc]\\nAnda dapat menjalankan serangkaian perintah seperti yang disebutkan di atas.', 'commands:[Router Y] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc],bot_reply:Untuk mengatur rute pada Router Y untuk jaringan lokal dengan alamat IP 192.168.3.0 dan subnet mask 255.255.255.0, langkah pertama adalah masuk ke mode konfigurasi menggunakan perintah berikut:\\n[Router Y] configure terminal\\nSelanjutnya, gunakan perintah `ip route` untuk menambahkan alamat IP tujuan, subnet mask, dan antarmuka. Akhir dari urutan perintah adalah sebagai berikut:\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\nend [eoc]Anda dapat melaksanakan rangkaian perintah sebagaimana dijelaskan di atas.', 'commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router B dan pendaftaran alamat IP 192.168.0.1 dan 192.168.2.0 pada perutean, perlu dinyatakan ppemanggilan konfigurasi Router B terlebih dahulu dengan perintah\\n[Router B] configure terminal\\nLalu tambahkan perintah router rip dan version 2 untuk menandakan akan digunakan protokol RIP versi 2\\nrouter rip\\nversion 2\\nSetelah itu cantumkan alamat IP asal dan alamat IP tujuan dengan menggunakan perintah network. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\nend [eoc]', 'commands:[Router Z] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router Z dan mendaftarkan alamat IP 192.168.0.1 dan 192.168.2.0 pada perutean, langkah awal adalah memasuki mode konfigurasi pada Router Z dengan perintah:\\n[Router Z] configure terminal\\nSetelah itu, gunakan perintah `router rip` dan `version 2` untuk menandakan bahwa Anda akan menggunakan protokol RIP versi 2:\\nrouter rip\\nversion 2\\nSelanjutnya, tambahkan alamat IP sumber dan tujuan dengan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Rangkaian perintah dapat dijalankan sebagai berikut:\\n[Router Z] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\nend [eoc]\\nAnda dapat melaksanakan rangkaian perintah seperti di atas.', 'commands:[Router I] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router I dan memasukkan alamat IP 192.168.0.1 dan 192.168.2.0 pada tabel routing, langkah awal adalah mengakses mode konfigurasi pada Router I menggunakan perintah berikut:\\n[Router I] configure terminal\\nAfterward, utilize the `router rip` and `version 2` commands to specify the use of RIP protocol version 2:\\nrouter rip\\nversion 2\\nSelanjutnya, gabungkan alamat IP sumber dan tujuan menggunakan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Perintah-perintah tersebut dapat dijalankan sebagai berikut:\\n[Router I] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\nend [eoc]\\nAnda dapat menerapkan urutan perintah seperti yang ditunjukkan di atas.', 'commands:[Router Z] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc],bot_reply:Untuk membuat rute pada Router Z melalui interface g/1/1/0 menuju jaringan lokal dengan IP 192.168.2.0, subnet mask 255.255.255.0 kita perlu menyatakan pemanggilan konfigurasi Router Z terlebih dahulu dengan menggunakan perintah\\n[Router Z] configure terminal\\nLalu dengan perintah ip route tambahkan alamat IP tujuan, subnet mask, dan interface. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router Z] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\nend [eoc]', 'commands:[Router A] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc],bot_reply:Untuk mengkonfigurasi rute pada Router A untuk jaringan lokal dengan alamat IP 192.168.2.0 dan subnet mask 255.255.255.0, Anda harus mulai dengan mengakses mode konfigurasi menggunakan perintah:\\n[Router A] configure terminal\\nSelanjutnya, tambahkan alamat IP tujuan, subnet mask, dan antarmuka menggunakan perintah `ip route`. Urutan perintah diakhiri dengan yang berikut:\\nip route 192.168.1.0 255.255.255.0 g1/1/0\\nend [eoc]\\nAnda dapat menjalankan serangkaian perintah seperti yang disebutkan di atas.', 'commands:[Router B] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc],bot_reply:Untuk mengatur rute pada Router B untuk jaringan lokal dengan alamat IP 192.168.2.0 dan subnet mask 255.255.255.0, langkah pertama adalah masuk ke mode konfigurasi menggunakan perintah berikut:\\n[Router B] configure terminal\\nSelanjutnya, gunakan perintah `ip route` untuk menambahkan alamat IP tujuan, subnet mask, dan antarmuka. Akhir dari urutan perintah adalah sebagai berikut:\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\nend [eoc]Anda dapat melaksanakan rangkaian perintah sebagaimana dijelaskan di atas.', 'commands:[Router K] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router K dan pendaftaran alamat IP 192.168.0.1 dan 192.168.3.0 pada perutean, perlu dinyatakan ppemanggilan konfigurasi Router K terlebih dahulu dengan perintah\\n[Router K] configure terminal\\nLalu tambahkan perintah router rip dan version 2 untuk menandakan akan digunakan protokol RIP versi 2\\nrouter rip\\nversion 2\\nSetelah itu cantumkan alamat IP asal dan alamat IP tujuan dengan menggunakan perintah network. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router K] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\nend [eoc]', 'commands:[Router G] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router G dan mendaftarkan alamat IP 192.168.0.1 dan 192.168.3.0 pada perutean, langkah awal adalah memasuki mode konfigurasi pada Router G dengan perintah:\\n[Router G] configure terminal\\nSetelah itu, gunakan perintah `router rip` dan `version 2` untuk menandakan bahwa Anda akan menggunakan protokol RIP versi 2:\\nrouter rip\\nversion 2\\nSelanjutnya, tambahkan alamat IP sumber dan tujuan dengan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Rangkaian perintah dapat dijalankan sebagai berikut:\\n[Router G] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\nend [eoc]\\nAnda dapat melaksanakan rangkaian perintah seperti di atas.', 'commands:[Router I] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router I dan memasukkan alamat IP 192.168.0.1 dan 192.168.3.0 pada tabel routing, langkah awal adalah mengakses mode konfigurasi pada Router I menggunakan perintah berikut:\\n[Router I] configure terminal\\nAfterward, utilize the `router rip` and `version 2` commands to specify the use of RIP protocol version 2:\\nrouter rip\\nversion 2\\nSelanjutnya, gabungkan alamat IP sumber dan tujuan menggunakan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Perintah-perintah tersebut dapat dijalankan sebagai berikut:\\n[Router I] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\nend [eoc]\\nAnda dapat menerapkan urutan perintah seperti yang ditunjukkan di atas.', 'commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router B dan pendaftaran alamat IP 192.168.1.0 dan 192.168.3.0 pada perutean, perlu dinyatakan ppemanggilan konfigurasi Router B terlebih dahulu dengan perintah\\n[Router B] configure terminal\\nLalu tambahkan perintah router rip dan version 2 untuk menandakan akan digunakan protokol RIP versi 2\\nrouter rip\\nversion 2\\nSetelah itu cantumkan alamat IP asal dan alamat IP tujuan dengan menggunakan perintah network. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\nend [eoc]', 'commands:[Router G] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router G dan mendaftarkan alamat IP 192.168.1.0 dan 192.168.3.0 pada perutean, langkah awal adalah memasuki mode konfigurasi pada Router G dengan perintah:\\n[Router G] configure terminal\\nSetelah itu, gunakan perintah `router rip` dan `version 2` untuk menandakan bahwa Anda akan menggunakan protokol RIP versi 2:\\nrouter rip\\nversion 2\\nSelanjutnya, tambahkan alamat IP sumber dan tujuan dengan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Rangkaian perintah dapat dijalankan sebagai berikut:\\n[Router G] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\nend [eoc]\\nAnda dapat melaksanakan rangkaian perintah seperti di atas.', 'commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router A dan memasukkan alamat IP 192.168.1.0 dan 192.168.3.0 pada tabel routing, langkah awal adalah mengakses mode konfigurasi pada Router A menggunakan perintah berikut:\\n[Router A] configure terminal\\nAfterward, utilize the `router rip` and `version 2` commands to specify the use of RIP protocol version 2:\\nrouter rip\\nversion 2\\nSelanjutnya, gabungkan alamat IP sumber dan tujuan menggunakan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Perintah-perintah tersebut dapat dijalankan sebagai berikut:\\n[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\nend [eoc]\\nAnda dapat menerapkan urutan perintah seperti yang ditunjukkan di atas.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(array['Prompt'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzIKqn8UUw46",
        "outputId": "38e62b6d-a482-4232-cf35-5f62c5b6687e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['prompt:Berikan daftar interface yang ada di Router A,commands:[Router A] show interfaces [eoc]', 'prompt:Saya membutuhkan informasi tentang semua interface di Router A,commands:[Router A] show interfaces [eoc]', 'prompt:Tunjukkan daftar semua interface yang tersedia di Router A,commands:[Router A] show interfaces [eoc]', 'prompt:Beri saya daftar semua antarmuka yang terhubung ke Router A,commands:[Router A] show interfaces [eoc]', 'prompt:Saya ingin melihat daftar interface di Router B,commands:[Router B] show interfaces [eoc]', 'prompt:Tolong berikan informasi tentang semua interface yang tersedia di Router B,commands:[Router B] show interfaces [eoc]', 'prompt:Tunjukkan saya daftar semua antarmuka di Router B,commands:[Router B] show interfaces [eoc]', 'prompt:Berikan daftar semua antarmuka yang terhubung ke Router C,commands:[Router C] show interfaces [eoc]', 'prompt:Saya memerlukan informasi tentang semua interface di Router C,commands:[Router C] show interfaces [eoc]', 'prompt:Tunjukkan semua interface yang tersedia di Router C,commands:[Router C] show interfaces [eoc]', 'prompt:Beri saya daftar semua antarmuka yang terhubung ke Router D,commands:[Router D] show interfaces [eoc]', 'prompt:Mohon informasi tentang semua interface di Router D,commands:[Router D] show interfaces [eoc]', 'prompt:Tolong tunjukkan daftar semua antarmuka di Router D,commands:[Router D] show interfaces [eoc]', 'prompt:Berikan daftar semua antarmuka yang terhubung ke Router internal,commands:[Router internal] show interfaces [eoc]', 'prompt:Saya membutuhkan informasi tentang semua interface di Router external,commands:[Router external] show interfaces [eoc]', 'prompt:Tolong tunjukkan daftar semua antarmuka di Router R1,commands:[Router R1] show interfaces [eoc]', 'prompt:Mohon berikan daftar semua antarmuka yang terhubung ke Router R2,commands:[Router R2] show interfaces [eoc]', 'prompt:Tolong berikan daftar interface untuk Router B Interface G0/0/0,commands:[Router B] show interface g0/0/0 [eoc]', 'prompt:Tunjukkan daftar interface yang tersedia di Router A Interface F0/0,commands:[Router A] show interface f0/0 [eoc]', 'prompt:Berikan daftar semua interface yang terhubung ke Router A Interface F0/1,commands:[Router A] show interface f0/1 [eoc]', 'prompt:Saya membutuhkan informasi tentang antarmuka F1/0 di Router A,commands:[Router A] show interface f1/0 [eoc]', 'prompt:Berikan daftar semua interface untuk Router B G0/1/1,commands:[Router B] show interface g0/1/1 [eoc]', 'prompt:Tolong tunjukkan daftar interface yang tersedia di Router B Interface G1/1/1,commands:[Router B] show interface g1/1/1 [eoc]', 'prompt:Beri saya daftar semua antarmuka yang tersedia di Router C F0/1,commands:[Router C] show interface f0/1 [eoc]', 'prompt:Saya membutuhkan informasi tentang interface G1/0/0 di Router R1,commands:[Router R1] show interface g1/0/0 [eoc]', 'prompt:Tunjukkan daftar semua interface yang terhubung ke Router R2 Interface G0/0/0,commands:[Router R2] show interface g0/0/0 [eoc]', 'prompt:Berikan daftar semua interface untuk Router R2 G0/0/1,commands:[Router R2] show interface g0/0/1 [eoc]', 'prompt:Tolong berikan daftar interface untuk Router R1 Interface F0/1,commands:[Router R1] show interface f0/1 [eoc]', 'prompt:Tolong ubah IP di Router C Interface X menjadi 192.168.1.1,commands:[Router C] configure terminal\\ninterface X\\nip address 192.168.1.1 255.255.255.0\\nend [eoc]', 'prompt:Ubah IP di Router A Interface G0/0/1 menjadi 10.0.0.1,commands:[Router A] configure terminal\\ninterface G0/0/1\\nip address 10.0.0.1 255.255.255.0\\nend [eoc]', 'prompt:Ubah IP di Router B Interface F0/1 menjadi 172.16.0.1,commands:[Router B] configure terminal\\ninterface F0/1\\nip address 172.16.0.1 255.255.255.0\\nend [eoc]', 'prompt:Tolong ubah IP di Internal Router Interface G1/0/0 menjadi 192.168.2.1,commands:[Internal Router] configure terminal\\ninterface G1/0/0\\nip address 192.168.2.1 255.255.255.0\\nend [eoc]', 'prompt:Saya butuh bantuan untuk mengubah IP di External Router Interface F1/0 menjadi 10.1.1.1,commands:[External Router] configure terminal\\ninterface F1/0\\nip address 10.1.1.1 255.255.255.0\\nend [eoc]', 'prompt:Mohon bantu untuk mengganti IP di R1 Interface G0/0/0 menjadi 192.168.3.1,commands:[Router R1] configure terminal\\ninterface G0/0/0\\nip address 192.168.3.1 255.255.255.0\\nend [eoc]', 'prompt:Mohon bantu untuk mengubah IP di Router D Interface F0/1 menjadi 172.16.10.1,commands:[Router D] configure terminal\\ninterface F0/1\\nip address 172.16.10.1 255.255.255.0\\nend [eoc]', 'prompt:Tolong ubah IP di Router E Interface G0/0 menjadi 192.168.5.1,commands:[Router E] configure terminal\\ninterface G0/0\\nip address 192.168.5.1 255.255.255.0\\nend [eoc]', 'prompt:Berikan bantuan untuk mengganti IP di Router F Interface F1/0 menjadi 10.1.2.1,commands:[Router F] configure terminal\\ninterface F1/0\\nip address 10.1.2.1 255.255.255.0\\nend [eoc]', 'prompt:Ubah IP di Router G Interface G0/0/1 menjadi 10.0.1.1,commands:[Router G] configure terminal\\ninterface G0/0/1\\nip address 10.0.1.1 255.255.255.0\\nend [eoc]', 'prompt:Mohon bantu untuk mengubah IP di R2 Interface F0/0 menjadi 192.168.4.1,commands:[Router R2] configure terminal\\ninterface F0/0\\nip address 192.168.4.1 255.255.255.0\\nend [eoc]', 'prompt:Tolong tambahkan kunci enkripsi ke Router D,commands:[Router D] configure terminal\\ncrypto key generate rsa\\nend [eoc]', 'prompt:Mohon tambahkan kunci enkripsi ke Router E,commands:[Router E] configure terminal\\ncrypto key generate rsa\\nend [eoc]', 'prompt:Tolong buat kunci enkripsi di Router F,commands:[Router F] configure terminal\\ncrypto key generate rsa\\nend [eoc]', 'prompt:Mohon tambahkan kunci enkripsi ke Router G,commands:[Router G] configure terminal\\ncrypto key generate rsa\\nend [eoc]', 'prompt:Tolong aktifkan enkripsi di Router H,commands:[Router H] configure terminal\\nservice password-encryption\\nend [eoc]', 'prompt:Mohon bantu untuk menambahkan kunci enkripsi di R1,commands:[Router R1] configure terminal\\ncrypto key generate rsa\\nend [eoc]', 'prompt:Saya ingin melihat daftar semua antarmuka di Router D,commands:[Router D] show interfaces [eoc]', 'prompt:Tunjukkan semua interface yang terhubung ke Router external,commands:[Router external] show interfaces [eoc]', 'prompt:Beri saya daftar semua antarmuka yang terhubung ke Router internal,commands:[Router internal] show interfaces [eoc]', 'prompt:Bagaimana cara mengkonfigurasi OSPF pada Router A?,commands:[Router A] router ospf 1\\nnetwork 10.0.0.0 0.255.255.255 area 0\\nend [eoc]', \"prompt:Berikan contoh penggunaan perintah 'ping' pada Router B,commands:[Router B] ping 10.0.0.1 [eoc]\", 'prompt:Bagaimana cara mengubah hostname pada Router C?,commands:[Router C] configure terminal\\nhostname NewHostName\\nend [eoc]', 'prompt:Saya ingin mengecek routing table pada Router A,commands:[Router A] show ip route [eoc]', 'prompt:Bagaimana cara mengkonfigurasi VLAN pada Switch A?,commands:[Switch A] vlan 10\\nname Sales\\nend [eoc]', 'prompt:Tolong buatkan ACL untuk memblokir akses ke situs web tertentu pada Router D,commands:[Router D] configure terminal\\naccess-list 101 deny tcp any host 192.168.1.2 eq 80\\naccess-list 101 permit ip any any\\ninterface gigabitEthernet 0/0\\nip access-group 101 in\\nend [eoc]', 'prompt:Bagaimana cara menampilkan port yang sedang aktif pada Switch B?,commands:[Switch B] show interface status [eoc]', 'prompt:Saya ingin mengkonfigurasi DHCP pada Router internal,commands:[Internal Router] configure terminal\\ndhcp pool InternalPool\\nnetwork 192.168.0.0 255.255.255.0\\ndefault-router 192.168.0.1\\nend [eoc]', 'prompt:Bagaimana cara menampilkan MAC address table pada Switch C?,commands:[Switch C] show mac-address-table [eoc]', 'prompt:Saya ingin mengkonfigurasi NAT pada Router external,commands:[Router external] configure terminal\\ninterface gigabitEthernet 0/0\\nip nat outside\\ninterface gigabitEthernet 0/1\\nip nat inside\\nip nat inside source list 1 interface gigabitEthernet 0/0 overload\\naccess-list 1 permit 192.168.0.0 0.0.255.255\\nend [eoc]', 'prompt:Bagaimana cara menampilkan log yang tersimpan pada Router R1?,commands:[Router R1] show logging [eoc]', 'prompt:Saya ingin memeriksa status koneksi pada Router R2,commands:[Router R2] show interfaces brief [eoc]', 'prompt:Bagaimana cara mengkonfigurasi trunking pada Switch D?,commands:[Switch D] interface gigabitEthernet 0/0\\nswitchport mode trunk\\nend [eoc]', 'prompt:Tolong buatkan static route pada Router internal untuk mengakses subnet 172.16.0.0/24 melalui Router A,commands:[Internal Router] ip route 172.16.0.0 255.255.255.0 10.0.0.2 [eoc]', 'prompt:Bagaimana cara menghapus VLAN yang tidak dibutuhkan pada Switch E?,commands:[Switch E] configure terminal\\nno vlan 10\\nend [eoc]', 'prompt:Saya ingin menampilkan informasi tentang status port pada Switch F,commands:[Switch F] show interface gigabitEthernet 0/1 [eoc]', 'prompt:Tunjukkan daftar konfigurasi yang ada di Router A,commands:[Router A] show running-config [eoc]', 'prompt:Beri saya daftar semua konfigurasi di Router A,commands:[Router A] show running-config [eoc]', 'prompt:Saya ingin melihat konfigurasi di Router B,commands:[Router B] show running-config [eoc]', 'prompt:Tolong berikan daftar semua konfigurasi di Router B,commands:[Router B] show running-config [eoc]', 'prompt:Berikan daftar semua konfigurasi di Router C,commands:[Router C] show running-config [eoc]', 'prompt:Saya memerlukan informasi tentang konfigurasi di Router C,commands:[Router C] show running-config [eoc]', 'prompt:Tunjukkan semua konfigurasi di Router D,commands:[Router D] show running-config [eoc]', 'prompt:Berikan daftar semua konfigurasi di Router internal,commands:[Router internal] show running-config [eoc]', 'prompt:Saya membutuhkan informasi tentang semua konfigurasi di Router external,commands:[Router external] show running-config [eoc]', 'prompt:Tolong tunjukkan daftar semua konfigurasi di Router R1,commands:[Router R1] show running-config [eoc]', 'prompt:Mohon berikan daftar semua konfigurasi di Router R2,commands:[Router R2] show running-config [eoc]', 'prompt:Tunjukkan daftar konfigurasi untuk Router B Interface G0/0/0,commands:[Router B] show running-config interface g0/0/0 [eoc]', 'prompt:Berikan konfigurasi untuk Router A Interface F0/0,commands:[Router A] show running-config interface f0/0 [eoc]', 'prompt:Saya membutuhkan informasi tentang konfigurasi di Router A Interface F0/1,commands:[Router A] show running-config interface f0/1 [eoc]', 'prompt:Tolong berikan konfigurasi untuk interface F1/0 di Router A,commands:[Router A] show running-config interface f1/0 [eoc]', 'prompt:Berikan konfigurasi untuk Router B G0/1/1,commands:[Router B] show running-config interface g0/1/1 [eoc]', 'prompt:Tunjukkan daftar konfigurasi yang terhubung ke Router B Interface G1/1/1,commands:[Router B] show running-config interface g1/1/1 [eoc]', 'prompt:Beri saya konfigurasi semua antarmuka yang tersedia di Router C F0/1,commands:[Router C] show running-config interface f0/1 [eoc]', 'prompt:Saya membutuhkan informasi tentang konfigurasi di interface G1/0/0 di Router R1,commands:[Router R1] show running-config interface g1/0/0 [eoc]', 'prompt:Tunjukkan daftar konfigurasi semua interface yang terhubung ke Router R2 Interface G0/0/0,commands:[Router R2] show running-config interface g0/0/0 [eoc]', 'prompt:Berikan konfigurasi untuk semua interface pada Router R2 G0/0/1,commands:[Router R2] show running-config interface g0/0/1 [eoc]', 'prompt:Beri saya daftar konfigurasi di Router D yang terkait dengan VLAN 10,commands:[Router D] show running-config | include vlan 10 [eoc]', 'prompt:Tunjukkan konfigurasi yang berhubungan dengan OSPF di Router A,commands:[Router A] show running-config | include ospf [eoc]', 'prompt:Beri saya daftar semua konfigurasi yang terkait dengan NAT di Router B,commands:[Router B] show running-config | include nat [eoc]', 'prompt:Saya ingin melihat daftar konfigurasi yang terkait dengan DHCP di Router C,commands:[Router C] show running-config | include dhcp [eoc]', 'prompt:Tolong tunjukkan daftar semua konfigurasi yang terkait dengan firewall di Router internal,commands:[Router internal] show running-config | include firewall [eoc]', 'prompt:Berikan konfigurasi untuk interface G0/0 di Router external,commands:[Router external] show running-config interface g0/0 [eoc]', 'prompt:Saya memerlukan informasi tentang konfigurasi VRF di Router R1,commands:[Router R1] show running-config | include vrf [eoc]', 'prompt:Tunjukkan daftar konfigurasi terkait dengan access-list di Router R2,commands:[Router R2] show running-config | include access-list [eoc]', 'prompt:Berikan daftar semua konfigurasi OSPF yang terkait dengan area 0 di Router A,commands:[Router A] show running-config | include ospf.*area 0 [eoc]', 'prompt:Saya ingin melihat konfigurasi NAT yang terkait dengan subnet 192.168.1.0/24 di Router B,commands:[Router B] show running-config | include nat.*192.168.1.0/24 [eoc]', 'prompt:Tolong berikan daftar konfigurasi BGP di Router C,commands:[Router C] show running-config | include bgp [eoc]', 'prompt:Saya membutuhkan informasi tentang konfigurasi QoS di Router internal,commands:[Router internal] show running-config | include qos [eoc]', 'prompt:Tunjukkan daftar konfigurasi yang terkait dengan MPLS di Router external,commands:[Router external] show running-config | include mpls [eoc]', 'prompt:Berikan konfigurasi untuk interface F0/1 di Router R1,commands:[Router R1] show running-config interface f0/1 [eoc]', 'prompt:Saya memerlukan informasi tentang konfigurasi VPC di Router R2,commands:[Router R2] show running-config | include vpc [eoc]', 'prompt:Tolong tunjukkan daftar konfigurasi yang terkait dengan IPsec di Router A,commands:[Router A] show running-config | include ipsec [eoc]', 'prompt:Tolong atur VLAN 10 pada Switch A dan hubungkan ke port GigabitEthernet1/0/5,commands:[Switch A] configure terminal\\nvlan 10\\nname VLAN10\\ninterface GigabitEthernet1/0/5\\nswitchport mode access\\nswitchport access vlan 10\\nend [eoc]', 'prompt:Tambahkan static route pada Router D untuk subnet 192.168.10.0/24 melalui Router B dengan metric 10,commands:[Router D] configure terminal\\nip route 192.168.10.0 255.255.255.0 Router B 10\\nend [eoc]', \"prompt:Tolong tambahkan user baru bernama 'john' dengan password 'password123' pada server MySQL,commands:CREATE USER 'john'@'localhost' IDENTIFIED BY 'password123';\\nGRANT ALL PRIVILEGES ON * . * TO 'john'@'localhost';\\nFLUSH PRIVILEGES; [eoc]\", 'prompt:Tolong tambahkan firewall rule pada server web untuk memblokir akses dari IP address 192.168.1.100,commands:sudo ufw deny from 192.168.1.100 [eoc]', 'prompt:Tolong buat konfigurasi NAT pada Router A untuk mengakses jaringan internal (192.168.1.0/24) dari internet,commands:[Router A] configure terminal\\ninterface GigabitEthernet0/0/1\\nip nat outside\\nexit\\ninterface GigabitEthernet0/0/0\\nip nat inside\\nexit\\nip nat inside source list 1 interface GigabitEthernet0/0/1 overload\\naccess-list 1 permit 192.168.1.0 0.0.0.255\\nend [eoc]', 'prompt:Buat route static menuju network 192.168.1.0 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0 di Router A,commands:[Router A] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Ciptakan skrip konfigurasi yang akan menetapkan route statis pada Router A untuk mengarahkan lalu lintas ke jaringan 192.168.1.0 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0,commands:[Router A] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Konfigurasikan routing statis di Router A untuk mengarahkan lalu lintas ke jaringan 192.168.1.0 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0,commands:[Router A] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Ciptakan konfigurasi perutean yang tepat pada Router A untuk memungkinkan lalu lintas menuju jaringan 192.168.1.0 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0,commands:[Router A] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Tulis skrip perutean yang diperlukan untuk mengarahkan semua paket menuju jaringan 192.168.1.0 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0 di Router A,commands:[Router A] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A dan perkenalkan network 192.168.2.0, 192.168.3.0,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Lakukan konfigurasi pada Router A untuk mengaktifkan protokol RIP versi 2 dan perkenalkan network 192.168.2.0 dan 192.168.3.0 ke dalam perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A dan pastikan network 192.168.2.0 dan 192.168.3.0 dikenali oleh perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Lakukan langkah-langkah untuk mengaktifkan protokol RIP versi 2 pada Router A dan pastikan network 192.168.2.0 dan 192.168.3.0 dapat diakses melalui perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A sekarang juga dan segera perkenalkan network 192.168.2.0 dan 192.168.3.0 ke dalam tabel perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 dengan IP address 192.168.0.1 subnet 255.255.255.0 pada interface g0/0 di Router A,commands:[Router A] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router A dan berikan IP address 192.168.0.1 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 11 pada interface g0/0 di Router A dengan IP address 192.168.0.1 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router A dan tetapkan IP address 192.168.0.1 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router A dan pastikan menggunakan IP address 192.168.0.1 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 dengan IP address 192.168.1.1 subnet 255.255.255.0 pada interface g0/0 di Router A,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router A dan berikan IP address 192.168.1.1 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 22 pada interface g0/0 di Router A dengan IP address 192.168.1.1 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router A dan tetapkan IP address 192.168.1.1 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router A dan pastikan menggunakan IP address 192.168.1.1 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 dengan IP address 192.168.2.1 subnet 255.255.255.0 pada interface g0/0 di Router A,commands:[Router A] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g0/0 di Router A dan berikan IP address 192.168.2.1 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 33 pada interface g0/0 di Router A dengan IP address 192.168.2.1 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g0/0 di Router A dan tetapkan IP address 192.168.2.1 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g0/0 di Router A dan pastikan menggunakan IP address 192.168.2.1 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Buat route static menuju network 192.168.0.1 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0 di Router B,commands:[Router B] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Ciptakan skrip konfigurasi yang akan menetapkan route statis pada Router B untuk mengarahkan lalu lintas ke jaringan 192.168.0.1 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0,commands:[Router B] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Konfigurasikan routing statis di Router B untuk mengarahkan lalu lintas ke jaringan 192.168.0.1 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0,commands:[Router B] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Ciptakan konfigurasi perutean yang tepat pada Router B untuk memungkinkan lalu lintas menuju jaringan 192.168.0.1 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0,commands:[Router B] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Tulis skrip perutean yang diperlukan untuk mengarahkan semua paket menuju jaringan 192.168.0.1 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0 di Router B,commands:[Router B] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router B dan perkenalkan network 192.168.1.0, 192.168.2.0,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Lakukan konfigurasi pada Router B untuk mengaktifkan protokol RIP versi 2 dan perkenalkan network 192.168.1.0 dan 192.168.2.0 ke dalam perutean,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router B dan pastikan network 192.168.1.0 dan 192.168.2.0 dikenali oleh perutean,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Lakukan langkah-langkah untuk mengaktifkan protokol RIP versi 2 pada Router B dan pastikan network 192.168.1.0 dan 192.168.2.0 dapat diakses melalui perutean,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router B sekarang juga dan segera perkenalkan network 192.168.1.0 dan 192.168.2.0 ke dalam tabel perutean,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 dengan IP address 192.168.0.2 subnet 255.255.255.0 pada interface g0/0 di Router B,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.2 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 11 pada interface g0/0 di Router B dengan IP address 192.168.0.2 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router B dan berikan IP address 192.168.0.2 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router B dan tetapkan IP address 192.168.0.2 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router B dan pastikan menggunakan IP address 192.168.0.2 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 dengan IP address 192.168.2.1 subnet 255.255.255.0 pada interface g0/0 di Router B,commands:[Router B] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router B dan berikan IP address 192.168.2.1 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 22 pada interface g0/0 di Router B dengan IP address 192.168.2.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router B dan tetapkan IP address 192.168.2.1 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router B dan pastikan menggunakan IP address 192.168.2.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.1 255.255.255.0\\n end [eoc]', 'prompt:Buat route static menuju network 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/0 di Router A,commands:[Router A] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc]', 'prompt:Ciptakan skrip konfigurasi yang akan menetapkan route statis pada Router A untuk mengarahkan lalu lintas ke jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/0,commands:[Router A] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc]', 'prompt:Konfigurasikan routing statis di Router A untuk mengarahkan lalu lintas ke jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/0,commands:[Router A] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc]', 'prompt:Ciptakan konfigurasi perutean yang tepat pada Router A untuk memungkinkan lalu lintas menuju jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/0,commands:[Router A] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc]', 'prompt:Tulis skrip perutean yang diperlukan untuk mengarahkan semua paket menuju jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/0 di Router A,commands:[Router A] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A dan perkenalkan network 192.168.0.1, 192.168.2.0,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Lakukan konfigurasi pada Router A untuk mengaktifkan protokol RIP versi 2 dan perkenalkan network 192.168.0.1 dan 192.168.2.0 ke dalam perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A dan pastikan network 192.168.0.1 dan 192.168.2.0 dikenali oleh perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Lakukan langkah-langkah untuk mengaktifkan protokol RIP versi 2 pada Router A dan pastikan network 192.168.0.1 dan 192.168.2.0 dapat diakses melalui perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A sekarang juga dan segera perkenalkan network 192.168.0.1 dan 192.168.2.0 ke dalam tabel perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc]', 'prompt:Buat route static menuju network 192.168.2.0 dengan subnet mask 255.255.255.0 melalui interface g/1/1/0 di Router A,commands:[Router A] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc]', 'prompt:Ciptakan skrip konfigurasi yang akan menetapkan route statis pada Router A untuk mengarahkan lalu lintas ke jaringan 192.168.2.0 dengan subnet mask 255.255.255.0 melalui interface g/1/1/0,commands:[Router A] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc]', 'prompt:Konfigurasikan routing statis di Router A untuk mengarahkan lalu lintas ke jaringan 192.168.2.0 dengan subnet mask 255.255.255.0 melalui interface g/1/1/0,commands:[Router A] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc]', 'prompt:Ciptakan konfigurasi perutean yang tepat pada Router A untuk memungkinkan lalu lintas menuju jaringan 192.168.2.0 dengan subnet mask 255.255.255.0 melalui interface g/1/1/0,commands:[Router A] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc]', 'prompt:Tulis skrip perutean yang diperlukan untuk mengarahkan semua paket menuju jaringan 192.168.2.0 dengan subnet mask 255.255.255.0 melalui interface g/1/1/0 di Router A,commands:[Router A] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A dan perkenalkan network 192.168.0.1, 192.168.3.0,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Aktifkan versi 2 dari protokol RIP di Router A dan tambahkan jaringan 192.168.0.1 dan 192.168.3.0 ke dalam konfigurasi.,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Menambahkan  jaringan dengan alamat IP 192.168.0.1 dan 192.168.3.0 ke dalam konfigurasi lalu aktifkan protokol RIP versi 2 pada Router A,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Tambahkan jaringan 192.168.0.1 dan 192.168.3.0 ke dalam konfigurasi, kemudian aktifkan protokol RIP versi 2 pada Router A,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Lakukan langkah-langkah untuk mengaktifkan protokol RIP versi 2 pada Router A dan pastikan network 192.168.0.1 dan 192.168.3.0 dapat diakses melalui perutean,commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router B dan perkenalkan network 192.168.1.0, 192.168.3.0,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Pada Router A, tambahkan network 192.168.0.1 serta 192.168.3.0 dan aktifkan protokol RIP versi 2,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Tambahkan jaringan 192.168.0.1 dan 192.168.3.0 ke dalam konfigurasi Router A, serta aktifkan protokol RIP versi 2.,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Aktifkan protokol RIP versi 2 pada Router A, serta pastikan jaringan 192.168.0.1 serta 192.168.3.0 sudah dikenali pada konfigurasi perutean,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Lakukan pengaktifan protokol RIP versi 2 pada Router A dan pastikan bahwa jaringan 192.168.0.1 dan 192.168.3.0 telah terdaftar dalam konfigurasi routing,commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 dengan IP address 192.168.0.1 subnet 255.255.255.0 pada interface g0/0 di Router B,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Mengaktifkan VLAN 33 pada antarmuka g0/0 di Router B dengan alamat IP 192.168.0.1 dan subnet 255.255.255.0.,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 33 pada interface g0/0 di Router B dengan IP address 192.168.0.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Konfigurasikan VLAN 33 pada antarmuka g0/0 di Router B dengan alamat IP 192.168.0.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan konfigurasi VLAN 33 pada interface g0/0 di Router B dengan alamat IP 192.168.0.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.1 255.255.255.0\\n end [eoc]', 'prompt:Buat route static menuju network 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/1 di Router B,commands:[Router B] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/1\\n end [eoc]', 'prompt:Lakukan konfigurasi yang menetapkan route statis pada Router B untuk mengarahkan lalu lintas ke jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/1,commands:[Router B] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/1\\n end [eoc]', 'prompt:Lakukan pengaturan konfigurasi pada Router B untuk mengonfigurasi rute statis yang mengarahkan lalu lintas ke jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui antarmuka g/1/0/1.,commands:[Router B] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/1\\n end [eoc]', 'prompt:Tulis skrip perutean yang diperlukan untuk mengarahkan semua paket menuju jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui interface g/1/0/1 di Router B,commands:[Router B] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/1\\n end [eoc]', 'prompt:Tuliskan skrip rute yang diperlukan untuk mengalihkan semua paket ke jaringan 192.168.3.0 dengan subnet mask 255.255.255.0 melalui antarmuka g/1/0/1 di Router B.,commands:[Router B] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/1\\n end [eoc]', 'prompt:Aktifkan VLAN 33 dengan IP address 192.168.3.0 subnet 255.255.255.0 pada interface g1/0 di Router B,commands:[Router B] configure terminal\\nint g1/0.33\\nencapsulation dot1q 33\\nip address 192.168.3.0 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 33 pada antarmuka g1/0 di Router B dengan IP address 192.168.3.0 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g1/0.33\\nencapsulation dot1q 33\\nip address 192.168.3.0 255.255.255.0\\n end [eoc]', 'prompt:Konfigurasikan VLAN 33 pada interface Router B g1/0 dengan alamat IP 192.168.3.0 dan subnet mask 255.255.255.0.,commands:[Router B] configure terminal\\nint g1/0.33\\nencapsulation dot1q 33\\nip address 192.168.3.0 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan konfigurasi VLAN 33 pada interface g1/0 di Router B dengan alamat IP 192.168.3.0 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g1/0.33\\nencapsulation dot1q 33\\nip address 192.168.3.0 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g1/0 di Router B dan pastikan menggunakan IP address 192.168.3.0 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g1/0.33\\nencapsulation dot1q 33\\nip address 192.168.3.0 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 dengan IP address 192.168.2.2 subnet 255.255.255.0 pada interface g0/1 di Router A,commands:[Router A] configure terminal\\nint g0/1.11\\nencapsulation dot1q 11\\nip address 192.168.2.2 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 11 pada interface g0/1 di Router A dengan IP address 192.168.2.2 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/1.11\\nencapsulation dot1q 11\\nip address 192.168.2.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/1 di Router A dan berikan IP address 192.168.2.2 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/1.11\\nencapsulation dot1q 11\\nip address 192.168.2.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/1 di Router A dan tetapkan IP address 192.168.2.2 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/1.11\\nencapsulation dot1q 11\\nip address 192.168.2.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/1 di Router A dan pastikan menggunakan IP address 192.168.2.2 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/1.11\\nencapsulation dot1q 11\\nip address 192.168.2.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 dengan IP address 192.168.1.1 subnet 255.255.255.0 pada interface g0/0 di Router B,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 33 pada antarmuka g0/0 di Router B dengan IP address 192.168.1.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Konfigurasikan VLAN 33 pada interface Router B g0/0 dengan alamat IP 192.168.1.1 dan subnet mask 255.255.255.0.,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan konfigurasi VLAN 33 pada interface g0/0 di Router B dengan alamat IP 192.168.1.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g0/0 di Router B dan pastikan menggunakan IP address 192.168.1.1 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.1.1 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 dengan IP address 192.168.0.3 subnet 255.255.255.0 pada interface g0/1 di Router B,commands:[Router B] configure terminal\\nint g0/1.22\\nencapsulation dot1q 22\\nip address 192.168.0.3 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 22 pada interface g0/1 di Router B dengan IP address 192.168.0.3 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/1.22\\nencapsulation dot1q 22\\nip address 192.168.0.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/1 di Router B dan berikan IP address 192.168.0.3 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/1.22\\nencapsulation dot1q 22\\nip address 192.168.0.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/1 di Router B dan tetapkan IP address 192.168.0.3 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/1.22\\nencapsulation dot1q 22\\nip address 192.168.0.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/1 di Router B dan pastikan menggunakan IP address 192.168.0.3 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/1.22\\nencapsulation dot1q 22\\nip address 192.168.0.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 dengan IP address 192.168.2.3 subnet 255.255.255.0 pada interface g0/0 di Router A,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 2 pada interface g0/0 di Router A dan berikan IP address 192.168.2.3 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.3 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 22 pada interface g0/0 di Router A dengan IP address 192.168.2.3 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router A dan tetapkan IP address 192.168.2.3 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g0/0 di Router A dan pastikan menggunakan IP address 192.168.2.3 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.2.3 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 dengan IP address 192.168.2.4 subnet 255.255.255.0 pada interface g1/1 di Router A,commands:[Router A] configure terminal\\nint g1/1.22\\nencapsulation dot1q 22\\nip address 192.168.2.4 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 22 pada interface g1/1 di Router A dengan IP address 192.168.2.4 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.22\\nencapsulation dot1q 22\\nip address 192.168.2.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g1/1 di Router A dan berikan IP address 192.168.2.4 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.22\\nencapsulation dot1q 22\\nip address 192.168.2.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g1/1 di Router A dan tetapkan IP address 192.168.2.4 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.22\\nencapsulation dot1q 22\\nip address 192.168.2.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 22 pada interface g1/1 di Router A dan pastikan menggunakan IP address 192.168.2.4 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.22\\nencapsulation dot1q 22\\nip address 192.168.2.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 dengan IP address 192.168.0.4 subnet 255.255.255.0 pada interface g0/0 di Router B,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g0/0 di Router B dan berikan IP address 192.168.0.4 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.4 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 33 pada interface g0/0 di Router B dengan IP address 192.168.0.4 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g0/0 di Router B dan tetapkan IP address 192.168.0.4 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 33 pada interface g0/0 di Router B dan pastikan menggunakan IP address 192.168.0.4 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.0.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 dengan IP address 192.168.1.2 subnet 255.255.255.0 pada interface g0/0 di Router B,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.1.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router B dan berikan IP address 192.168.1.2 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.1.2 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 11 pada interface g0/0 di Router B dengan IP address 192.168.1.2 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.1.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router B dan tetapkan IP address 192.168.1.2 dengan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.1.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g0/0 di Router B dan pastikan menggunakan IP address 192.168.1.2 dan subnet 255.255.255.0,commands:[Router B] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.1.2 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 dengan IP address 192.168.1.4 subnet 255.255.255.0 pada interface g1/1 di Router A,commands:[Router A] configure terminal\\nint g1/1.11\\nencapsulation dot1q 11\\nip address 192.168.1.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g1/1 di Router A dan berikan IP address 192.168.1.4 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.11\\nencapsulation dot1q 11\\nip address 192.168.1.4 255.255.255.0\\n end [eoc]', 'prompt:Lakukan konfigurasi VLAN 11 pada interface g1/1 di Router A dengan IP address 192.168.1.4 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.11\\nencapsulation dot1q 11\\nip address 192.168.1.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g1/1 di Router A dan tetapkan IP address 192.168.1.4 dengan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.11\\nencapsulation dot1q 11\\nip address 192.168.1.4 255.255.255.0\\n end [eoc]', 'prompt:Aktifkan VLAN 11 pada interface g1/1 di Router A dan pastikan menggunakan IP address 192.168.1.4 dan subnet 255.255.255.0,commands:[Router A] configure terminal\\nint g1/1.11\\nencapsulation dot1q 11\\nip address 192.168.1.4 255.255.255.0\\n end [eoc]', 'commands:[Router Z] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc],bot_reply:Untuk membuat rute pada Router Z melalui interface g/0/0/0 menuju jaringan lokal dengan IP 192.168.1.0, subnet mask 255.255.255.0 kita perlu menyatakan pemanggilan konfigurasi Router Z terlebih dahulu dengan menggunakan perintah\\n[Router Z] configure terminal\\nLalu dengan perintah ip route tambahkan alamat IP tujuan, subnet mask, dan interface. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router Z] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\nend [eoc]', 'commands:[Router I] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc],bot_reply:Untuk mengkonfigurasi rute pada Router I untuk jaringan lokal dengan alamat IP 192.168.1.0 dan subnet mask 255.255.255.0, Anda harus mulai dengan mengakses mode konfigurasi menggunakan perintah:\\n[Router I] configure terminal\\nSelanjutnya, tambahkan alamat IP tujuan, subnet mask, dan antarmuka menggunakan perintah `ip route`. Urutan perintah diakhiri dengan yang berikut:\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\nend [eoc]\\nAnda dapat menjalankan serangkaian perintah seperti yang disebutkan di atas.', 'commands:[Router X] configure terminal\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\n end [eoc],bot_reply:Untuk mengatur rute pada Router X untuk jaringan lokal dengan alamat IP 192.168.1.0 dan subnet mask 255.255.255.0, langkah pertama adalah masuk ke mode konfigurasi menggunakan perintah berikut:\\n[Router X] configure terminal\\nSelanjutnya, gunakan perintah `ip route` untuk menambahkan alamat IP tujuan, subnet mask, dan antarmuka. Akhir dari urutan perintah adalah sebagai berikut:\\nip route 192.168.1.0 255.255.255.0 g0/0/0\\nend [eoc]Anda dapat melaksanakan rangkaian perintah sebagaimana dijelaskan di atas.', 'commands:[Router C] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router C dan pendaftaran alamat IP 192.168.2.0 dan 192.168.3.0 pada perutean, perlu dinyatakan ppemanggilan konfigurasi Router C terlebih dahulu dengan perintah\\n[Router C] configure terminal\\nLalu tambahkan perintah router rip dan version 2 untuk menandakan akan digunakan protokol RIP versi 2\\nrouter rip\\nversion 2\\nSetelah itu cantumkan alamat IP asal dan alamat IP tujuan dengan menggunakan perintah network. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router C] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\nend [eoc]', 'commands:[Router K] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router K dan mendaftarkan alamat IP 192.168.2.0 dan 192.168.3.0 pada perutean, langkah awal adalah memasuki mode konfigurasi pada Router K dengan perintah:\\n[Router K] configure terminal\\nSetelah itu, gunakan perintah `router rip` dan `version 2` untuk menandakan bahwa Anda akan menggunakan protokol RIP versi 2:\\nrouter rip\\nversion 2\\nSelanjutnya, tambahkan alamat IP sumber dan tujuan dengan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Rangkaian perintah dapat dijalankan sebagai berikut:\\n[Router K] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\nend [eoc]\\nAnda dapat melaksanakan rangkaian perintah seperti di atas.', 'commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router A dan memasukkan alamat IP 192.168.2.0 dan 192.168.3.0 pada tabel routing, langkah awal adalah mengakses mode konfigurasi pada Router A menggunakan perintah berikut:\\n[Router A] configure terminal\\nAfterward, utilize the `router rip` and `version 2` commands to specify the use of RIP protocol version 2:\\nrouter rip\\nversion 2\\nSelanjutnya, gabungkan alamat IP sumber dan tujuan menggunakan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Perintah-perintah tersebut dapat dijalankan sebagai berikut:\\n[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.2.0\\nnetwork 192.168.3.0\\nend [eoc]\\nAnda dapat menerapkan urutan perintah seperti yang ditunjukkan di atas.', 'commands:[Router K] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc],bot_reply:Untuk mengaktifkan VLAN 11 pada Router K dengan interface g0/0, alamat IP 192.168.0.1, dan subnet mask 255.255.255.0 kita perlu menyatakan pemanggilan konfigurasi Router K terlebih dahulu dengan menggunakan perintah\\n[Router K] configure terminal\\nLalu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask dapat digunakan perintah int, encapsulation, dan ip address\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router K] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\nend [eoc]', 'commands:[Router G] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc],bot_reply:Untuk mengaktifkan VLAN 11 pada Router G dengan alamat IP 192.168.0.1, interface g0/0, dan subnet mask 255.255.255.0  perlu dilakukan pemanggilan konfigurasi Router G terlebih dahulu dengan menggunakan perintah\\n[Router G] configure terminal\\nSetelah itu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask dapat digunakan perintah int, encapsulation, dan ip address\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah adalah sebagai berikut:\\n[Router G] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\nend [eoc]', 'commands:[Router A] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\n end [eoc],bot_reply:Anda dapat mengaktifkan VLAN 11 pada Router A dengan alamat IP 192.168.0.1, interface g0/0, dan subnet mask 255.255.255.0 dengan langkah pertama melakukan pemanggilan konfigurasi Router A terlebih dahulu dengan menggunakan perintah\\n[Router A] configure terminal\\nLalu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask gunakan perintah int, encapsulation, dan ip address\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Perintah lengkapnya, yaitu:\\n[Router A] configure terminal\\nint g0/0.11\\nencapsulation dot1q 11\\nip address 192.168.0.1 255.255.255.0\\nend [eoc]', 'commands:[Router G] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc],bot_reply:Untuk mengaktifkan VLAN 22 pada Router G dengan alamat IP 192.168.1.1, interface g0/0, dan subnet mask 255.255.255.0  perlu dilakukan pemanggilan konfigurasi Router G terlebih dahulu dengan menggunakan perintah\\n[Router G] configure terminal\\nSetelah itu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask dapat digunakan perintah int, encapsulation, dan ip address\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah adalah sebagai berikut:\\n[Router G] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\nend [eoc]', 'commands:[Router O] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc],bot_reply:Untuk mengaktifkan VLAN 22 pada Router O dengan interface g0/0, alamat IP 192.168.2.1, dan subnet mask 255.255.255.0 kita perlu menyatakan pemanggilan konfigurasi Router O terlebih dahulu dengan menggunakan perintah\\n[Router O] configure terminal\\nLalu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask dapat digunakan perintah int, encapsulation, dan ip address\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router O] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nend [eoc]', 'commands:[Router I] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\n end [eoc],bot_reply:Anda dapat mengaktifkan VLAN 22 pada Router I dengan alamat IP 192.168.1.1, interface g0/0, dan subnet mask 255.255.255.0 dengan langkah pertama melakukan pemanggilan konfigurasi Router I terlebih dahulu dengan menggunakan perintah\\n[Router I] configure terminal\\nLalu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask gunakan perintah int, encapsulation, dan ip address\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Perintah lengkapnya, yaitu:\\n[Router I] configure terminal\\nint g0/0.22\\nencapsulation dot1q 22\\nip address 192.168.1.1 255.255.255.0\\nend [eoc]', 'commands:[Router A] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc],bot_reply:Untuk mengaktifkan VLAN 33 pada Router A dengan alamat IP 192.168.2.1, interface g0/0, dan subnet mask 255.255.255.0  perlu dilakukan pemanggilan konfigurasi Router A terlebih dahulu dengan menggunakan perintah\\n[Router A] configure terminal\\nSetelah itu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask dapat digunakan perintah int, encapsulation, dan ip address\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah adalah sebagai berikut:\\n[Router A] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nend [eoc]', 'commands:[Router I] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc],bot_reply:Untuk mengaktifkan VLAN 33 pada Router I dengan interface g0/0, alamat IP 192.168.2.1, dan subnet mask 255.255.255.0 kita perlu menyatakan pemanggilan konfigurasi Router I terlebih dahulu dengan menggunakan perintah\\n[Router I] configure terminal\\nLalu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask dapat digunakan perintah int, encapsulation, dan ip address\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router I] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nend [eoc]', 'commands:[Router Z] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\n end [eoc],bot_reply:Anda dapat mengaktifkan VLAN 33 pada Router Z dengan alamat IP 192.168.2.1, interface g0/0, dan subnet mask 255.255.255.0 dengan langkah pertama melakukan pemanggilan konfigurasi Router Z terlebih dahulu dengan menggunakan perintah\\n[Router Z] configure terminal\\nLalu berdasarkan interface, tipe vlan, alamat IP, dan subnet mask gunakan perintah int, encapsulation, dan ip address\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nRangkaian perintah diakhiri dengan end [eoc]. Perintah lengkapnya, yaitu:\\n[Router Z] configure terminal\\nint g0/0.33\\nencapsulation dot1q 33\\nip address 192.168.2.1 255.255.255.0\\nend [eoc]', 'commands:[Router K] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc],bot_reply:Untuk membuat rute pada Router K melalui interface g/0/0/0 menuju jaringan lokal dengan IP 192.168.0.1, subnet mask 255.255.255.0 kita perlu menyatakan pemanggilan konfigurasi Router K terlebih dahulu dengan menggunakan perintah\\n[Router K] configure terminal\\nLalu dengan perintah ip route tambahkan alamat IP tujuan, subnet mask, dan interface. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router K] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\nend [eoc]', 'commands:[Router K] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc],bot_reply:Untuk mengkonfigurasi rute pada Router K untuk jaringan lokal dengan alamat IP 192.168.0.1 dan subnet mask 255.255.255.0, Anda harus mulai dengan mengakses mode konfigurasi menggunakan perintah:\\n[Router K] configure terminal\\nSelanjutnya, tambahkan alamat IP tujuan, subnet mask, dan antarmuka menggunakan perintah `ip route`. Urutan perintah diakhiri dengan yang berikut:\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\nend [eoc]\\nAnda dapat menjalankan serangkaian perintah seperti yang disebutkan di atas.', 'commands:[Router C] configure terminal\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\n end [eoc],bot_reply:Untuk mengatur rute pada Router C untuk jaringan lokal dengan alamat IP 192.168.0.1 dan subnet mask 255.255.255.0, langkah pertama adalah masuk ke mode konfigurasi menggunakan perintah berikut:\\n[Router C] configure terminal\\nSelanjutnya, gunakan perintah `ip route` untuk menambahkan alamat IP tujuan, subnet mask, dan antarmuka. Akhir dari urutan perintah adalah sebagai berikut:\\nip route 192.168.0.1 255.255.255.0 g0/0/0\\nend [eoc]Anda dapat melaksanakan rangkaian perintah sebagaimana dijelaskan di atas.', 'commands:[Router X] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router X dan pendaftaran alamat IP 192.168.1.0 dan 192.168.2.0 pada perutean, perlu dinyatakan ppemanggilan konfigurasi Router X terlebih dahulu dengan perintah\\n[Router X] configure terminal\\nLalu tambahkan perintah router rip dan version 2 untuk menandakan akan digunakan protokol RIP versi 2\\nrouter rip\\nversion 2\\nSetelah itu cantumkan alamat IP asal dan alamat IP tujuan dengan menggunakan perintah network. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router X] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\nend [eoc]', 'commands:[Router Y] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router Y dan mendaftarkan alamat IP 192.168.1.0 dan 192.168.2.0 pada perutean, langkah awal adalah memasuki mode konfigurasi pada Router Y dengan perintah:\\n[Router Y] configure terminal\\nSetelah itu, gunakan perintah `router rip` dan `version 2` untuk menandakan bahwa Anda akan menggunakan protokol RIP versi 2:\\nrouter rip\\nversion 2\\nSelanjutnya, tambahkan alamat IP sumber dan tujuan dengan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Rangkaian perintah dapat dijalankan sebagai berikut:\\n[Router Y] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\nend [eoc]\\nAnda dapat melaksanakan rangkaian perintah seperti di atas.', 'commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router B dan memasukkan alamat IP 192.168.1.0 dan 192.168.2.0 pada tabel routing, langkah awal adalah mengakses mode konfigurasi pada Router B menggunakan perintah berikut:\\n[Router B] configure terminal\\nAfterward, utilize the `router rip` and `version 2` commands to specify the use of RIP protocol version 2:\\nrouter rip\\nversion 2\\nSelanjutnya, gabungkan alamat IP sumber dan tujuan menggunakan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Perintah-perintah tersebut dapat dijalankan sebagai berikut:\\n[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.2.0\\nend [eoc]\\nAnda dapat menerapkan urutan perintah seperti yang ditunjukkan di atas.', 'commands:[Router B] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc],bot_reply:Untuk membuat rute pada Router B melalui interface g/1/0/0 menuju jaringan lokal dengan IP 192.168.3.0, subnet mask 255.255.255.0 kita perlu menyatakan pemanggilan konfigurasi Router B terlebih dahulu dengan menggunakan perintah\\n[Router B] configure terminal\\nLalu dengan perintah ip route tambahkan alamat IP tujuan, subnet mask, dan interface. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router B] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\nend [eoc]', 'commands:[Router Y] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc],bot_reply:Untuk mengkonfigurasi rute pada Router Y untuk jaringan lokal dengan alamat IP 192.168.3.0 dan subnet mask 255.255.255.0, Anda harus mulai dengan mengakses mode konfigurasi menggunakan perintah:\\n[Router Y] configure terminal\\nSelanjutnya, tambahkan alamat IP tujuan, subnet mask, dan antarmuka menggunakan perintah `ip route`. Urutan perintah diakhiri dengan yang berikut:\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\nend [eoc]\\nAnda dapat menjalankan serangkaian perintah seperti yang disebutkan di atas.', 'commands:[Router Y] configure terminal\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\n end [eoc],bot_reply:Untuk mengatur rute pada Router Y untuk jaringan lokal dengan alamat IP 192.168.3.0 dan subnet mask 255.255.255.0, langkah pertama adalah masuk ke mode konfigurasi menggunakan perintah berikut:\\n[Router Y] configure terminal\\nSelanjutnya, gunakan perintah `ip route` untuk menambahkan alamat IP tujuan, subnet mask, dan antarmuka. Akhir dari urutan perintah adalah sebagai berikut:\\nip route 192.168.3.0 255.255.255.0 g1/0/0\\nend [eoc]Anda dapat melaksanakan rangkaian perintah sebagaimana dijelaskan di atas.', 'commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router B dan pendaftaran alamat IP 192.168.0.1 dan 192.168.2.0 pada perutean, perlu dinyatakan ppemanggilan konfigurasi Router B terlebih dahulu dengan perintah\\n[Router B] configure terminal\\nLalu tambahkan perintah router rip dan version 2 untuk menandakan akan digunakan protokol RIP versi 2\\nrouter rip\\nversion 2\\nSetelah itu cantumkan alamat IP asal dan alamat IP tujuan dengan menggunakan perintah network. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\nend [eoc]', 'commands:[Router Z] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router Z dan mendaftarkan alamat IP 192.168.0.1 dan 192.168.2.0 pada perutean, langkah awal adalah memasuki mode konfigurasi pada Router Z dengan perintah:\\n[Router Z] configure terminal\\nSetelah itu, gunakan perintah `router rip` dan `version 2` untuk menandakan bahwa Anda akan menggunakan protokol RIP versi 2:\\nrouter rip\\nversion 2\\nSelanjutnya, tambahkan alamat IP sumber dan tujuan dengan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Rangkaian perintah dapat dijalankan sebagai berikut:\\n[Router Z] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\nend [eoc]\\nAnda dapat melaksanakan rangkaian perintah seperti di atas.', 'commands:[Router I] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router I dan memasukkan alamat IP 192.168.0.1 dan 192.168.2.0 pada tabel routing, langkah awal adalah mengakses mode konfigurasi pada Router I menggunakan perintah berikut:\\n[Router I] configure terminal\\nAfterward, utilize the `router rip` and `version 2` commands to specify the use of RIP protocol version 2:\\nrouter rip\\nversion 2\\nSelanjutnya, gabungkan alamat IP sumber dan tujuan menggunakan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Perintah-perintah tersebut dapat dijalankan sebagai berikut:\\n[Router I] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.2.0\\nend [eoc]\\nAnda dapat menerapkan urutan perintah seperti yang ditunjukkan di atas.', 'commands:[Router Z] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc],bot_reply:Untuk membuat rute pada Router Z melalui interface g/1/1/0 menuju jaringan lokal dengan IP 192.168.2.0, subnet mask 255.255.255.0 kita perlu menyatakan pemanggilan konfigurasi Router Z terlebih dahulu dengan menggunakan perintah\\n[Router Z] configure terminal\\nLalu dengan perintah ip route tambahkan alamat IP tujuan, subnet mask, dan interface. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router Z] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\nend [eoc]', 'commands:[Router A] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc],bot_reply:Untuk mengkonfigurasi rute pada Router A untuk jaringan lokal dengan alamat IP 192.168.2.0 dan subnet mask 255.255.255.0, Anda harus mulai dengan mengakses mode konfigurasi menggunakan perintah:\\n[Router A] configure terminal\\nSelanjutnya, tambahkan alamat IP tujuan, subnet mask, dan antarmuka menggunakan perintah `ip route`. Urutan perintah diakhiri dengan yang berikut:\\nip route 192.168.1.0 255.255.255.0 g1/1/0\\nend [eoc]\\nAnda dapat menjalankan serangkaian perintah seperti yang disebutkan di atas.', 'commands:[Router B] configure terminal\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\n end [eoc],bot_reply:Untuk mengatur rute pada Router B untuk jaringan lokal dengan alamat IP 192.168.2.0 dan subnet mask 255.255.255.0, langkah pertama adalah masuk ke mode konfigurasi menggunakan perintah berikut:\\n[Router B] configure terminal\\nSelanjutnya, gunakan perintah `ip route` untuk menambahkan alamat IP tujuan, subnet mask, dan antarmuka. Akhir dari urutan perintah adalah sebagai berikut:\\nip route 192.168.2.0 255.255.255.0 g1/1/0\\nend [eoc]Anda dapat melaksanakan rangkaian perintah sebagaimana dijelaskan di atas.', 'commands:[Router K] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router K dan pendaftaran alamat IP 192.168.0.1 dan 192.168.3.0 pada perutean, perlu dinyatakan ppemanggilan konfigurasi Router K terlebih dahulu dengan perintah\\n[Router K] configure terminal\\nLalu tambahkan perintah router rip dan version 2 untuk menandakan akan digunakan protokol RIP versi 2\\nrouter rip\\nversion 2\\nSetelah itu cantumkan alamat IP asal dan alamat IP tujuan dengan menggunakan perintah network. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router K] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\nend [eoc]', 'commands:[Router G] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router G dan mendaftarkan alamat IP 192.168.0.1 dan 192.168.3.0 pada perutean, langkah awal adalah memasuki mode konfigurasi pada Router G dengan perintah:\\n[Router G] configure terminal\\nSetelah itu, gunakan perintah `router rip` dan `version 2` untuk menandakan bahwa Anda akan menggunakan protokol RIP versi 2:\\nrouter rip\\nversion 2\\nSelanjutnya, tambahkan alamat IP sumber dan tujuan dengan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Rangkaian perintah dapat dijalankan sebagai berikut:\\n[Router G] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\nend [eoc]\\nAnda dapat melaksanakan rangkaian perintah seperti di atas.', 'commands:[Router I] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router I dan memasukkan alamat IP 192.168.0.1 dan 192.168.3.0 pada tabel routing, langkah awal adalah mengakses mode konfigurasi pada Router I menggunakan perintah berikut:\\n[Router I] configure terminal\\nAfterward, utilize the `router rip` and `version 2` commands to specify the use of RIP protocol version 2:\\nrouter rip\\nversion 2\\nSelanjutnya, gabungkan alamat IP sumber dan tujuan menggunakan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Perintah-perintah tersebut dapat dijalankan sebagai berikut:\\n[Router I] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.0.1\\nnetwork 192.168.3.0\\nend [eoc]\\nAnda dapat menerapkan urutan perintah seperti yang ditunjukkan di atas.', 'commands:[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router B dan pendaftaran alamat IP 192.168.1.0 dan 192.168.3.0 pada perutean, perlu dinyatakan ppemanggilan konfigurasi Router B terlebih dahulu dengan perintah\\n[Router B] configure terminal\\nLalu tambahkan perintah router rip dan version 2 untuk menandakan akan digunakan protokol RIP versi 2\\nrouter rip\\nversion 2\\nSetelah itu cantumkan alamat IP asal dan alamat IP tujuan dengan menggunakan perintah network. Rangkaian perintah diakhiri dengan end [eoc]. Rangkaian perintah dapat dilakukan sebagai berikut:\\n[Router B] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\nend [eoc]', 'commands:[Router G] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router G dan mendaftarkan alamat IP 192.168.1.0 dan 192.168.3.0 pada perutean, langkah awal adalah memasuki mode konfigurasi pada Router G dengan perintah:\\n[Router G] configure terminal\\nSetelah itu, gunakan perintah `router rip` dan `version 2` untuk menandakan bahwa Anda akan menggunakan protokol RIP versi 2:\\nrouter rip\\nversion 2\\nSelanjutnya, tambahkan alamat IP sumber dan tujuan dengan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Rangkaian perintah dapat dijalankan sebagai berikut:\\n[Router G] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\nend [eoc]\\nAnda dapat melaksanakan rangkaian perintah seperti di atas.', 'commands:[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\n end [eoc],bot_reply:Untuk mengaktifkan protokol RIP versi 2 pada Router A dan memasukkan alamat IP 192.168.1.0 dan 192.168.3.0 pada tabel routing, langkah awal adalah mengakses mode konfigurasi pada Router A menggunakan perintah berikut:\\n[Router A] configure terminal\\nAfterward, utilize the `router rip` and `version 2` commands to specify the use of RIP protocol version 2:\\nrouter rip\\nversion 2\\nSelanjutnya, gabungkan alamat IP sumber dan tujuan menggunakan perintah `network`. Urutan perintah diakhiri dengan `end [eoc]`. Perintah-perintah tersebut dapat dijalankan sebagai berikut:\\n[Router A] configure terminal\\nrouter rip\\nversion 2\\nnetwork 192.168.1.0\\nnetwork 192.168.3.0\\nend [eoc]\\nAnda dapat menerapkan urutan perintah seperti yang ditunjukkan di atas.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset('csv', data_files={'train': '/content/train_data.csv'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224,
          "referenced_widgets": [
            "3caced0d3704481da0da5baaaa114d65",
            "f900f96c2eed4278a279e2db0e9c4121",
            "829cbe4c5af146e2a2774ca82bf702a1",
            "478873d35e5a4a49bae11ef3c1d0b402",
            "dee774a7ffa54e9bb352704bfe58fc77",
            "06b816fa81284ac8afd181ee845f6264",
            "fc4d53bf0f4e4f38bf4a88de768cde03",
            "427ec3c6e4bb41b7887628ee6e9f01a7",
            "feb7917df7f7408e9dc5e362fcbb5115",
            "7b5e02346ae24e4ba2f0eeff146ff478",
            "1679795e195746c88acc6f823c60e640",
            "c1258d508b314da0aa71c96267a19e7b",
            "239dccdd25d24af3a641d15f7476c990",
            "89f4c9b019c4432ba46e4f0ecba12e9f",
            "0ea906785629497eaed5d80c6ac41d15",
            "c4cabc25bf2e42b09148c9e1930c09e7",
            "755d53e43b224bc098655795369af689",
            "4531fc438fed43538db156b884e413a1",
            "69f897b8f8bc4e36a380f7c993cec403",
            "69cd3856b2774c31a634a6d57c00588a",
            "30c9c548920c4f6ea5b76ccf3f8d0682",
            "f43a05f679954fd0a714118b17a53402",
            "c61a0e30cb354e19a2350a73f17ad635",
            "5b805d968fe94da1a63730318ea7a685",
            "cecb879ef4d54c58a93f49b845b2029a",
            "a3bcca7e819a4589b7abafb9e33aeba7",
            "0e46f5807d1444efb41a9ccbf19d315f",
            "f519d78f0b5444b2ae6b81eb749bac9d",
            "2073fc76a311420bb6c73e04c1da2057",
            "54890cc2bf694de5a4482de2d6495fc5",
            "eee0ac813dcf4c7d8d80175775a0333a",
            "4cf0e6346238429baad647cadac1878e",
            "5fdfc7049566472c88e723a09f11de60"
          ]
        },
        "id": "NJtC9t7CU9CI",
        "outputId": "b2cc3c6e-23fe-47f2-cf53-89d82608533d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default-ac9108a6de025a6c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-ac9108a6de025a6c/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3caced0d3704481da0da5baaaa114d65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1258d508b314da0aa71c96267a19e7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-ac9108a6de025a6c/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv/csv.py:170: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
            "  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c61a0e30cb354e19a2350a73f17ad635"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"Prompt\"], padding=True, truncation=True, max_length= 1024)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"Prompt\"])\n",
        "tokenized_datasets.set_format(\"torch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "f29c63837b6b4a7da7ebd01d3a6a8328",
            "61a656fcf7334729898bb0c6b8977692",
            "3cec74bbc2e74f7dafa874b89a5430aa",
            "16f6ee1d4919412e8fceb4eead2af10b",
            "b4e0fd1db62c44c2969aef20bdb10987",
            "85d31c01b4774477a612da269cb5843e",
            "5d6143b7586b48059efae07e229a746a",
            "ab7e55e60f8c44f1a23d6378e68fdeb6",
            "13c699a92fec47c4881f131c5e707529",
            "b1e49badb1e34579b7e1a1b7efceac21",
            "3e511cc729be4128aa5bead005153678"
          ]
        },
        "id": "YUKgFbxbU96E",
        "outputId": "561bb468-acc3-4fe1-e859-6a2c491e87ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.fingerprint:Parameter 'function'=<function tokenize_function at 0x7ecb8357ea70> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f29c63837b6b4a7da7ebd01d3a6a8328"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "full_train_dataset = tokenized_datasets[\"train\"]\n",
        "train_dataloader = DataLoader(full_train_dataset, shuffle=False, batch_size=8)"
      ],
      "metadata": {
        "id": "-dltOiMdVZDs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_adapters(model, adapter_dim=4, p = 0.1):\n",
        "    assert adapter_dim > 0\n",
        "\n",
        "    for name, module in model.named_modules():\n",
        "      if isinstance(module, FrozenBNBLinear):\n",
        "          if \"attn\" in name or \"mlp\" in name or \"head\" in name:\n",
        "              print(\"Adding adapter to\", name)\n",
        "              module.adapter = nn.Sequential(\n",
        "                nn.Linear(module.in_features, adapter_dim, bias=False),\n",
        "                nn.Dropout(p=p),\n",
        "                nn.Linear(adapter_dim, module.out_features, bias=False),\n",
        "            )\n",
        "              print(\"Initializing\", name)\n",
        "              nn.init.zeros_(module.adapter[2].weight)\n",
        "\n",
        "          else:\n",
        "              print(\"Not adding adapter to\", name)\n",
        "      elif isinstance(module, FrozenBNBEmbedding):\n",
        "          print(\"Adding adapter to\", name)\n",
        "          module.adapter = nn.Sequential(\n",
        "                nn.Embedding(module.num_embeddings, adapter_dim),\n",
        "                nn.Dropout(p=p),\n",
        "                nn.Linear(adapter_dim, module.embedding_dim, bias=False),\n",
        "            )\n",
        "          print(\"Initializing\", name)\n",
        "          nn.init.zeros_(module.adapter[2].weight)\n",
        "\n",
        "add_adapters(gpt)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "gpt.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfOYSNP0VZHl",
        "outputId": "602fbb64-76ae-490f-891b-9d3e74abd0d4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding adapter to transformer.wte\n",
            "Initializing transformer.wte\n",
            "Adding adapter to transformer.h.0.attn.k_proj\n",
            "Initializing transformer.h.0.attn.k_proj\n",
            "Adding adapter to transformer.h.0.attn.v_proj\n",
            "Initializing transformer.h.0.attn.v_proj\n",
            "Adding adapter to transformer.h.0.attn.q_proj\n",
            "Initializing transformer.h.0.attn.q_proj\n",
            "Adding adapter to transformer.h.0.attn.out_proj\n",
            "Initializing transformer.h.0.attn.out_proj\n",
            "Adding adapter to transformer.h.0.mlp.fc_in\n",
            "Initializing transformer.h.0.mlp.fc_in\n",
            "Adding adapter to transformer.h.0.mlp.fc_out\n",
            "Initializing transformer.h.0.mlp.fc_out\n",
            "Adding adapter to transformer.h.1.attn.k_proj\n",
            "Initializing transformer.h.1.attn.k_proj\n",
            "Adding adapter to transformer.h.1.attn.v_proj\n",
            "Initializing transformer.h.1.attn.v_proj\n",
            "Adding adapter to transformer.h.1.attn.q_proj\n",
            "Initializing transformer.h.1.attn.q_proj\n",
            "Adding adapter to transformer.h.1.attn.out_proj\n",
            "Initializing transformer.h.1.attn.out_proj\n",
            "Adding adapter to transformer.h.1.mlp.fc_in\n",
            "Initializing transformer.h.1.mlp.fc_in\n",
            "Adding adapter to transformer.h.1.mlp.fc_out\n",
            "Initializing transformer.h.1.mlp.fc_out\n",
            "Adding adapter to transformer.h.2.attn.k_proj\n",
            "Initializing transformer.h.2.attn.k_proj\n",
            "Adding adapter to transformer.h.2.attn.v_proj\n",
            "Initializing transformer.h.2.attn.v_proj\n",
            "Adding adapter to transformer.h.2.attn.q_proj\n",
            "Initializing transformer.h.2.attn.q_proj\n",
            "Adding adapter to transformer.h.2.attn.out_proj\n",
            "Initializing transformer.h.2.attn.out_proj\n",
            "Adding adapter to transformer.h.2.mlp.fc_in\n",
            "Initializing transformer.h.2.mlp.fc_in\n",
            "Adding adapter to transformer.h.2.mlp.fc_out\n",
            "Initializing transformer.h.2.mlp.fc_out\n",
            "Adding adapter to transformer.h.3.attn.k_proj\n",
            "Initializing transformer.h.3.attn.k_proj\n",
            "Adding adapter to transformer.h.3.attn.v_proj\n",
            "Initializing transformer.h.3.attn.v_proj\n",
            "Adding adapter to transformer.h.3.attn.q_proj\n",
            "Initializing transformer.h.3.attn.q_proj\n",
            "Adding adapter to transformer.h.3.attn.out_proj\n",
            "Initializing transformer.h.3.attn.out_proj\n",
            "Adding adapter to transformer.h.3.mlp.fc_in\n",
            "Initializing transformer.h.3.mlp.fc_in\n",
            "Adding adapter to transformer.h.3.mlp.fc_out\n",
            "Initializing transformer.h.3.mlp.fc_out\n",
            "Adding adapter to transformer.h.4.attn.k_proj\n",
            "Initializing transformer.h.4.attn.k_proj\n",
            "Adding adapter to transformer.h.4.attn.v_proj\n",
            "Initializing transformer.h.4.attn.v_proj\n",
            "Adding adapter to transformer.h.4.attn.q_proj\n",
            "Initializing transformer.h.4.attn.q_proj\n",
            "Adding adapter to transformer.h.4.attn.out_proj\n",
            "Initializing transformer.h.4.attn.out_proj\n",
            "Adding adapter to transformer.h.4.mlp.fc_in\n",
            "Initializing transformer.h.4.mlp.fc_in\n",
            "Adding adapter to transformer.h.4.mlp.fc_out\n",
            "Initializing transformer.h.4.mlp.fc_out\n",
            "Adding adapter to transformer.h.5.attn.k_proj\n",
            "Initializing transformer.h.5.attn.k_proj\n",
            "Adding adapter to transformer.h.5.attn.v_proj\n",
            "Initializing transformer.h.5.attn.v_proj\n",
            "Adding adapter to transformer.h.5.attn.q_proj\n",
            "Initializing transformer.h.5.attn.q_proj\n",
            "Adding adapter to transformer.h.5.attn.out_proj\n",
            "Initializing transformer.h.5.attn.out_proj\n",
            "Adding adapter to transformer.h.5.mlp.fc_in\n",
            "Initializing transformer.h.5.mlp.fc_in\n",
            "Adding adapter to transformer.h.5.mlp.fc_out\n",
            "Initializing transformer.h.5.mlp.fc_out\n",
            "Adding adapter to transformer.h.6.attn.k_proj\n",
            "Initializing transformer.h.6.attn.k_proj\n",
            "Adding adapter to transformer.h.6.attn.v_proj\n",
            "Initializing transformer.h.6.attn.v_proj\n",
            "Adding adapter to transformer.h.6.attn.q_proj\n",
            "Initializing transformer.h.6.attn.q_proj\n",
            "Adding adapter to transformer.h.6.attn.out_proj\n",
            "Initializing transformer.h.6.attn.out_proj\n",
            "Adding adapter to transformer.h.6.mlp.fc_in\n",
            "Initializing transformer.h.6.mlp.fc_in\n",
            "Adding adapter to transformer.h.6.mlp.fc_out\n",
            "Initializing transformer.h.6.mlp.fc_out\n",
            "Adding adapter to transformer.h.7.attn.k_proj\n",
            "Initializing transformer.h.7.attn.k_proj\n",
            "Adding adapter to transformer.h.7.attn.v_proj\n",
            "Initializing transformer.h.7.attn.v_proj\n",
            "Adding adapter to transformer.h.7.attn.q_proj\n",
            "Initializing transformer.h.7.attn.q_proj\n",
            "Adding adapter to transformer.h.7.attn.out_proj\n",
            "Initializing transformer.h.7.attn.out_proj\n",
            "Adding adapter to transformer.h.7.mlp.fc_in\n",
            "Initializing transformer.h.7.mlp.fc_in\n",
            "Adding adapter to transformer.h.7.mlp.fc_out\n",
            "Initializing transformer.h.7.mlp.fc_out\n",
            "Adding adapter to transformer.h.8.attn.k_proj\n",
            "Initializing transformer.h.8.attn.k_proj\n",
            "Adding adapter to transformer.h.8.attn.v_proj\n",
            "Initializing transformer.h.8.attn.v_proj\n",
            "Adding adapter to transformer.h.8.attn.q_proj\n",
            "Initializing transformer.h.8.attn.q_proj\n",
            "Adding adapter to transformer.h.8.attn.out_proj\n",
            "Initializing transformer.h.8.attn.out_proj\n",
            "Adding adapter to transformer.h.8.mlp.fc_in\n",
            "Initializing transformer.h.8.mlp.fc_in\n",
            "Adding adapter to transformer.h.8.mlp.fc_out\n",
            "Initializing transformer.h.8.mlp.fc_out\n",
            "Adding adapter to transformer.h.9.attn.k_proj\n",
            "Initializing transformer.h.9.attn.k_proj\n",
            "Adding adapter to transformer.h.9.attn.v_proj\n",
            "Initializing transformer.h.9.attn.v_proj\n",
            "Adding adapter to transformer.h.9.attn.q_proj\n",
            "Initializing transformer.h.9.attn.q_proj\n",
            "Adding adapter to transformer.h.9.attn.out_proj\n",
            "Initializing transformer.h.9.attn.out_proj\n",
            "Adding adapter to transformer.h.9.mlp.fc_in\n",
            "Initializing transformer.h.9.mlp.fc_in\n",
            "Adding adapter to transformer.h.9.mlp.fc_out\n",
            "Initializing transformer.h.9.mlp.fc_out\n",
            "Adding adapter to transformer.h.10.attn.k_proj\n",
            "Initializing transformer.h.10.attn.k_proj\n",
            "Adding adapter to transformer.h.10.attn.v_proj\n",
            "Initializing transformer.h.10.attn.v_proj\n",
            "Adding adapter to transformer.h.10.attn.q_proj\n",
            "Initializing transformer.h.10.attn.q_proj\n",
            "Adding adapter to transformer.h.10.attn.out_proj\n",
            "Initializing transformer.h.10.attn.out_proj\n",
            "Adding adapter to transformer.h.10.mlp.fc_in\n",
            "Initializing transformer.h.10.mlp.fc_in\n",
            "Adding adapter to transformer.h.10.mlp.fc_out\n",
            "Initializing transformer.h.10.mlp.fc_out\n",
            "Adding adapter to transformer.h.11.attn.k_proj\n",
            "Initializing transformer.h.11.attn.k_proj\n",
            "Adding adapter to transformer.h.11.attn.v_proj\n",
            "Initializing transformer.h.11.attn.v_proj\n",
            "Adding adapter to transformer.h.11.attn.q_proj\n",
            "Initializing transformer.h.11.attn.q_proj\n",
            "Adding adapter to transformer.h.11.attn.out_proj\n",
            "Initializing transformer.h.11.attn.out_proj\n",
            "Adding adapter to transformer.h.11.mlp.fc_in\n",
            "Initializing transformer.h.11.mlp.fc_in\n",
            "Adding adapter to transformer.h.11.mlp.fc_out\n",
            "Initializing transformer.h.11.mlp.fc_out\n",
            "Adding adapter to transformer.h.12.attn.k_proj\n",
            "Initializing transformer.h.12.attn.k_proj\n",
            "Adding adapter to transformer.h.12.attn.v_proj\n",
            "Initializing transformer.h.12.attn.v_proj\n",
            "Adding adapter to transformer.h.12.attn.q_proj\n",
            "Initializing transformer.h.12.attn.q_proj\n",
            "Adding adapter to transformer.h.12.attn.out_proj\n",
            "Initializing transformer.h.12.attn.out_proj\n",
            "Adding adapter to transformer.h.12.mlp.fc_in\n",
            "Initializing transformer.h.12.mlp.fc_in\n",
            "Adding adapter to transformer.h.12.mlp.fc_out\n",
            "Initializing transformer.h.12.mlp.fc_out\n",
            "Adding adapter to transformer.h.13.attn.k_proj\n",
            "Initializing transformer.h.13.attn.k_proj\n",
            "Adding adapter to transformer.h.13.attn.v_proj\n",
            "Initializing transformer.h.13.attn.v_proj\n",
            "Adding adapter to transformer.h.13.attn.q_proj\n",
            "Initializing transformer.h.13.attn.q_proj\n",
            "Adding adapter to transformer.h.13.attn.out_proj\n",
            "Initializing transformer.h.13.attn.out_proj\n",
            "Adding adapter to transformer.h.13.mlp.fc_in\n",
            "Initializing transformer.h.13.mlp.fc_in\n",
            "Adding adapter to transformer.h.13.mlp.fc_out\n",
            "Initializing transformer.h.13.mlp.fc_out\n",
            "Adding adapter to transformer.h.14.attn.k_proj\n",
            "Initializing transformer.h.14.attn.k_proj\n",
            "Adding adapter to transformer.h.14.attn.v_proj\n",
            "Initializing transformer.h.14.attn.v_proj\n",
            "Adding adapter to transformer.h.14.attn.q_proj\n",
            "Initializing transformer.h.14.attn.q_proj\n",
            "Adding adapter to transformer.h.14.attn.out_proj\n",
            "Initializing transformer.h.14.attn.out_proj\n",
            "Adding adapter to transformer.h.14.mlp.fc_in\n",
            "Initializing transformer.h.14.mlp.fc_in\n",
            "Adding adapter to transformer.h.14.mlp.fc_out\n",
            "Initializing transformer.h.14.mlp.fc_out\n",
            "Adding adapter to transformer.h.15.attn.k_proj\n",
            "Initializing transformer.h.15.attn.k_proj\n",
            "Adding adapter to transformer.h.15.attn.v_proj\n",
            "Initializing transformer.h.15.attn.v_proj\n",
            "Adding adapter to transformer.h.15.attn.q_proj\n",
            "Initializing transformer.h.15.attn.q_proj\n",
            "Adding adapter to transformer.h.15.attn.out_proj\n",
            "Initializing transformer.h.15.attn.out_proj\n",
            "Adding adapter to transformer.h.15.mlp.fc_in\n",
            "Initializing transformer.h.15.mlp.fc_in\n",
            "Adding adapter to transformer.h.15.mlp.fc_out\n",
            "Initializing transformer.h.15.mlp.fc_out\n",
            "Adding adapter to transformer.h.16.attn.k_proj\n",
            "Initializing transformer.h.16.attn.k_proj\n",
            "Adding adapter to transformer.h.16.attn.v_proj\n",
            "Initializing transformer.h.16.attn.v_proj\n",
            "Adding adapter to transformer.h.16.attn.q_proj\n",
            "Initializing transformer.h.16.attn.q_proj\n",
            "Adding adapter to transformer.h.16.attn.out_proj\n",
            "Initializing transformer.h.16.attn.out_proj\n",
            "Adding adapter to transformer.h.16.mlp.fc_in\n",
            "Initializing transformer.h.16.mlp.fc_in\n",
            "Adding adapter to transformer.h.16.mlp.fc_out\n",
            "Initializing transformer.h.16.mlp.fc_out\n",
            "Adding adapter to transformer.h.17.attn.k_proj\n",
            "Initializing transformer.h.17.attn.k_proj\n",
            "Adding adapter to transformer.h.17.attn.v_proj\n",
            "Initializing transformer.h.17.attn.v_proj\n",
            "Adding adapter to transformer.h.17.attn.q_proj\n",
            "Initializing transformer.h.17.attn.q_proj\n",
            "Adding adapter to transformer.h.17.attn.out_proj\n",
            "Initializing transformer.h.17.attn.out_proj\n",
            "Adding adapter to transformer.h.17.mlp.fc_in\n",
            "Initializing transformer.h.17.mlp.fc_in\n",
            "Adding adapter to transformer.h.17.mlp.fc_out\n",
            "Initializing transformer.h.17.mlp.fc_out\n",
            "Adding adapter to transformer.h.18.attn.k_proj\n",
            "Initializing transformer.h.18.attn.k_proj\n",
            "Adding adapter to transformer.h.18.attn.v_proj\n",
            "Initializing transformer.h.18.attn.v_proj\n",
            "Adding adapter to transformer.h.18.attn.q_proj\n",
            "Initializing transformer.h.18.attn.q_proj\n",
            "Adding adapter to transformer.h.18.attn.out_proj\n",
            "Initializing transformer.h.18.attn.out_proj\n",
            "Adding adapter to transformer.h.18.mlp.fc_in\n",
            "Initializing transformer.h.18.mlp.fc_in\n",
            "Adding adapter to transformer.h.18.mlp.fc_out\n",
            "Initializing transformer.h.18.mlp.fc_out\n",
            "Adding adapter to transformer.h.19.attn.k_proj\n",
            "Initializing transformer.h.19.attn.k_proj\n",
            "Adding adapter to transformer.h.19.attn.v_proj\n",
            "Initializing transformer.h.19.attn.v_proj\n",
            "Adding adapter to transformer.h.19.attn.q_proj\n",
            "Initializing transformer.h.19.attn.q_proj\n",
            "Adding adapter to transformer.h.19.attn.out_proj\n",
            "Initializing transformer.h.19.attn.out_proj\n",
            "Adding adapter to transformer.h.19.mlp.fc_in\n",
            "Initializing transformer.h.19.mlp.fc_in\n",
            "Adding adapter to transformer.h.19.mlp.fc_out\n",
            "Initializing transformer.h.19.mlp.fc_out\n",
            "Adding adapter to transformer.h.20.attn.k_proj\n",
            "Initializing transformer.h.20.attn.k_proj\n",
            "Adding adapter to transformer.h.20.attn.v_proj\n",
            "Initializing transformer.h.20.attn.v_proj\n",
            "Adding adapter to transformer.h.20.attn.q_proj\n",
            "Initializing transformer.h.20.attn.q_proj\n",
            "Adding adapter to transformer.h.20.attn.out_proj\n",
            "Initializing transformer.h.20.attn.out_proj\n",
            "Adding adapter to transformer.h.20.mlp.fc_in\n",
            "Initializing transformer.h.20.mlp.fc_in\n",
            "Adding adapter to transformer.h.20.mlp.fc_out\n",
            "Initializing transformer.h.20.mlp.fc_out\n",
            "Adding adapter to transformer.h.21.attn.k_proj\n",
            "Initializing transformer.h.21.attn.k_proj\n",
            "Adding adapter to transformer.h.21.attn.v_proj\n",
            "Initializing transformer.h.21.attn.v_proj\n",
            "Adding adapter to transformer.h.21.attn.q_proj\n",
            "Initializing transformer.h.21.attn.q_proj\n",
            "Adding adapter to transformer.h.21.attn.out_proj\n",
            "Initializing transformer.h.21.attn.out_proj\n",
            "Adding adapter to transformer.h.21.mlp.fc_in\n",
            "Initializing transformer.h.21.mlp.fc_in\n",
            "Adding adapter to transformer.h.21.mlp.fc_out\n",
            "Initializing transformer.h.21.mlp.fc_out\n",
            "Adding adapter to transformer.h.22.attn.k_proj\n",
            "Initializing transformer.h.22.attn.k_proj\n",
            "Adding adapter to transformer.h.22.attn.v_proj\n",
            "Initializing transformer.h.22.attn.v_proj\n",
            "Adding adapter to transformer.h.22.attn.q_proj\n",
            "Initializing transformer.h.22.attn.q_proj\n",
            "Adding adapter to transformer.h.22.attn.out_proj\n",
            "Initializing transformer.h.22.attn.out_proj\n",
            "Adding adapter to transformer.h.22.mlp.fc_in\n",
            "Initializing transformer.h.22.mlp.fc_in\n",
            "Adding adapter to transformer.h.22.mlp.fc_out\n",
            "Initializing transformer.h.22.mlp.fc_out\n",
            "Adding adapter to transformer.h.23.attn.k_proj\n",
            "Initializing transformer.h.23.attn.k_proj\n",
            "Adding adapter to transformer.h.23.attn.v_proj\n",
            "Initializing transformer.h.23.attn.v_proj\n",
            "Adding adapter to transformer.h.23.attn.q_proj\n",
            "Initializing transformer.h.23.attn.q_proj\n",
            "Adding adapter to transformer.h.23.attn.out_proj\n",
            "Initializing transformer.h.23.attn.out_proj\n",
            "Adding adapter to transformer.h.23.mlp.fc_in\n",
            "Initializing transformer.h.23.mlp.fc_in\n",
            "Adding adapter to transformer.h.23.mlp.fc_out\n",
            "Initializing transformer.h.23.mlp.fc_out\n",
            "Adding adapter to transformer.h.24.attn.k_proj\n",
            "Initializing transformer.h.24.attn.k_proj\n",
            "Adding adapter to transformer.h.24.attn.v_proj\n",
            "Initializing transformer.h.24.attn.v_proj\n",
            "Adding adapter to transformer.h.24.attn.q_proj\n",
            "Initializing transformer.h.24.attn.q_proj\n",
            "Adding adapter to transformer.h.24.attn.out_proj\n",
            "Initializing transformer.h.24.attn.out_proj\n",
            "Adding adapter to transformer.h.24.mlp.fc_in\n",
            "Initializing transformer.h.24.mlp.fc_in\n",
            "Adding adapter to transformer.h.24.mlp.fc_out\n",
            "Initializing transformer.h.24.mlp.fc_out\n",
            "Adding adapter to transformer.h.25.attn.k_proj\n",
            "Initializing transformer.h.25.attn.k_proj\n",
            "Adding adapter to transformer.h.25.attn.v_proj\n",
            "Initializing transformer.h.25.attn.v_proj\n",
            "Adding adapter to transformer.h.25.attn.q_proj\n",
            "Initializing transformer.h.25.attn.q_proj\n",
            "Adding adapter to transformer.h.25.attn.out_proj\n",
            "Initializing transformer.h.25.attn.out_proj\n",
            "Adding adapter to transformer.h.25.mlp.fc_in\n",
            "Initializing transformer.h.25.mlp.fc_in\n",
            "Adding adapter to transformer.h.25.mlp.fc_out\n",
            "Initializing transformer.h.25.mlp.fc_out\n",
            "Adding adapter to transformer.h.26.attn.k_proj\n",
            "Initializing transformer.h.26.attn.k_proj\n",
            "Adding adapter to transformer.h.26.attn.v_proj\n",
            "Initializing transformer.h.26.attn.v_proj\n",
            "Adding adapter to transformer.h.26.attn.q_proj\n",
            "Initializing transformer.h.26.attn.q_proj\n",
            "Adding adapter to transformer.h.26.attn.out_proj\n",
            "Initializing transformer.h.26.attn.out_proj\n",
            "Adding adapter to transformer.h.26.mlp.fc_in\n",
            "Initializing transformer.h.26.mlp.fc_in\n",
            "Adding adapter to transformer.h.26.mlp.fc_out\n",
            "Initializing transformer.h.26.mlp.fc_out\n",
            "Adding adapter to transformer.h.27.attn.k_proj\n",
            "Initializing transformer.h.27.attn.k_proj\n",
            "Adding adapter to transformer.h.27.attn.v_proj\n",
            "Initializing transformer.h.27.attn.v_proj\n",
            "Adding adapter to transformer.h.27.attn.q_proj\n",
            "Initializing transformer.h.27.attn.q_proj\n",
            "Adding adapter to transformer.h.27.attn.out_proj\n",
            "Initializing transformer.h.27.attn.out_proj\n",
            "Adding adapter to transformer.h.27.mlp.fc_in\n",
            "Initializing transformer.h.27.mlp.fc_in\n",
            "Adding adapter to transformer.h.27.mlp.fc_out\n",
            "Initializing transformer.h.27.mlp.fc_out\n",
            "Adding adapter to lm_head\n",
            "Initializing lm_head\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTJForCausalLM(\n",
              "  (transformer): GPTJModel(\n",
              "    (wte): FrozenBNBEmbedding(50400, 4096)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-27): 28 x GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): FrozenBNBLinear(4096, 50400)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bitsandbytes.optim import Adam8bit\n",
        "\n",
        "gpt.gradient_checkpointing_enable()\n",
        "optimizer = Adam8bit(gpt.parameters(), lr=1e-5, weight_decay=0.01)"
      ],
      "metadata": {
        "id": "H5wlNkmzVdNs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "print(num_training_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60nFwOiDVdRX",
        "outputId": "26e811fa-f2c5-4ee4-bc4f-96a9b4b26a62"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "    optimizer, int(num_training_steps*0.1), num_training_steps\n",
        ")"
      ],
      "metadata": {
        "id": "ka6evBnRVkO_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "train_loss_values = []\n",
        "train_acc_values = []\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "gpt.train()\n",
        "gpt.gradient_checkpointing_enable()\n",
        "k = 0\n",
        "\n",
        "metrics_path = '/content/metrics.json'\n",
        "batch_size = 8\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    num_samples = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "\n",
        "        k = k + 1\n",
        "        if k % 500 == 0:\n",
        "          print(k)\n",
        "          state = {'k' : k, 'epoch': num_epochs, 'lr_scheduler': lr_scheduler.state_dict(), 'state_dict': gpt.state_dict(), 'optimizer': optimizer.state_dict()}\n",
        "          gpt.save_pretrained(f\"/content/model-step-{k}/\")\n",
        "\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "          out = gpt.forward(**batch,)\n",
        "\n",
        "          loss = F.cross_entropy(out.logits[:, :-1, :].flatten(0, -2), batch['input_ids'][:, 1:].flatten(),\n",
        "                                reduction='mean', label_smoothing=0.1)\n",
        "\n",
        "        print(loss)\n",
        "\n",
        "        # calculate accuracy\n",
        "        preds = torch.argmax(out.logits[:, :-1, :], axis=-1)\n",
        "        acc = (preds == batch['input_ids'][:, 1:]).float().mean()\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(gpt.parameters(), 1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * batch_size\n",
        "        running_acc += acc.item() * batch_size\n",
        "        num_samples += batch_size\n",
        "\n",
        "        lr_scheduler.step()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    epoch_loss = running_loss / num_samples\n",
        "    epoch_acc = running_acc / num_samples\n",
        "\n",
        "    # Append the loss and accuracy values to the respective lists\n",
        "    train_loss_values.append(epoch_loss)\n",
        "    train_acc_values.append(epoch_acc)\n",
        "\n",
        "    # Print the metrics for this epoch\n",
        "    print(f\"Epoch {epoch+1}: train_loss = {epoch_loss:.3f}, train_acc = {epoch_acc:.3f}\")\n",
        "\n",
        "gpt.save_pretrained(\"/content/model/\", state_dict=gpt.state_dict(), save_training_args=True)\n",
        "# torch.save(gpt.state_dict(), \"/content/weights.pth\")\n",
        "metrics = {'train_loss': train_loss_values, 'train_acc': train_acc_values}\n",
        "torch.save(metrics, metrics_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ce33ab792ce140e798a16733326df896",
            "2e2da550410e4ce584d01f230aa86aac",
            "04d097bdba3842f2b0f19fdf88cc3c59",
            "db677177b7954606883e49a8cda799d3",
            "b9a2f5cf892f4b6daf2eadf866830852",
            "bdaecdea645b4e81acd65a685c45b661",
            "2a81192b51ec40c08d003930425597fa",
            "45468f1c3a744c67bc5548aae76636ec",
            "141474c0f6d9403c93e7a7c24b79250d",
            "2173f65886b94747977e3342c996910d",
            "e946fe5d89a441dfb4781339ca53dcdd"
          ]
        },
        "id": "XHC9D5NXVkR8",
        "outputId": "7fe21e41-f486-40f0-ae84-2c00b16a190e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce33ab792ce140e798a16733326df896",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/680 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11.5087, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11.6020, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11.1991, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.8654, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.4940, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11.4325, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11.0552, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11.0081, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11.4182, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11.2030, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.9757, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.9744, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.7601, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.5811, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.7195, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.7651, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.5862, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.7390, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.7882, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.5261, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.5969, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.6399, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.6122, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.6765, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.6780, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.7124, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.6687, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.6883, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.1464, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.4191, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.4452, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.8910, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.5270, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.9640, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train_loss = 9.437, train_acc = 0.196\n",
            "tensor(11.2360, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11.2993, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.9105, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.5571, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.1883, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11.0672, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.7036, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.6468, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(11.0385, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.8106, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.5692, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.5625, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.3387, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.1990, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.3119, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.3197, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.1497, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.2941, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.2890, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.0775, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.1200, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.1693, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.0678, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.1093, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.0927, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.1041, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.0467, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.0417, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.5417, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.2747, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.2972, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.6951, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.3586, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.8401, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train_loss = 9.039, train_acc = 0.197\n",
            "tensor(10.3632, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.3670, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.0402, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.6719, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.3360, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.0996, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.7951, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.6903, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.0270, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.8028, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.5507, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.5416, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.3267, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.3243, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.3898, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.3373, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.1965, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.3220, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.2494, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.1200, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.1368, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.1862, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.0048, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.0208, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7.9630, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7.9571, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7.8909, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7.8581, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7.4389, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.9778, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.9896, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.3283, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.0523, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.6164, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train_loss = 8.146, train_acc = 0.201\n",
            "tensor(8.9424, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.9050, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.6321, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.2901, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.0281, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.6689, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.4236, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.3187, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.5622, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.3379, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.1191, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(8.1360, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7.9479, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7.0874, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7.1050, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.9946, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.9101, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7.0210, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.8832, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.8631, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.8460, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.9051, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.6517, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.6549, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.5670, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.5473, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.4805, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.4270, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.1211, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.7017, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.6927, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.9712, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.7665, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.4556, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: train_loss = 6.940, train_acc = 0.200\n",
            "tensor(7.2657, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7.2389, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.9324, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.6034, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.4145, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7.0172, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.8091, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.7035, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.8674, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.5986, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.4102, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.4891, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.3427, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5.5758, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5.5691, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5.3512, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5.3202, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5.4486, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5.1561, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5.3158, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5.2304, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5.3392, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.9042, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.8814, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.8225, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.7456, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.6786, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.5401, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.4051, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.4340, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.4093, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.5879, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.4705, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.3051, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train_loss = 5.476, train_acc = 0.199\n",
            "tensor(4.9643, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.9904, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.5843, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.1010, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.9847, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.6581, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.4137, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.3203, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4.2096, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.7476, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.5869, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.5329, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.4246, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.9097, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.9312, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6273, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6951, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.7855, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5678, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.7807, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.7530, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.7214, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6959, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.7429, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6820, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6893, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6858, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6979, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.7217, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.0607, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.0450, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.0658, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.0776, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.0810, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: train_loss = 3.339, train_acc = 0.555\n",
            "tensor(2.6004, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6069, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6265, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6640, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.7023, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6584, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6696, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6674, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5666, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5403, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5504, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5687, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6178, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5926, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5473, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.4551, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5319, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5159, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.4225, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5654, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5390, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5325, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.4408, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.4485, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3697, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3523, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3392, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3209, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3940, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.9436, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.9153, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.9587, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.9587, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.9502, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: train_loss = 2.592, train_acc = 0.842\n",
            "tensor(2.4000, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.4176, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3428, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2902, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3516, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.4175, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3969, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.4282, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2800, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2695, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2993, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3010, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3828, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3998, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3355, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2764, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3698, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3184, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2732, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3757, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3681, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.3302, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2969, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2907, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1995, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1943, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1738, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1584, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2379, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.8651, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.8469, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.8781, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.8833, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.8985, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: train_loss = 2.398, train_acc = 0.885\n",
            "tensor(2.2311, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2713, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1902, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1334, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2124, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2753, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2672, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2695, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1437, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1228, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1636, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1560, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2345, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2689, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1837, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1177, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2233, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1768, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1262, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2430, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2420, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.2102, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1702, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1660, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0735, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0739, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0571, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0462, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1253, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.7918, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.7786, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.8019, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.8104, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.8211, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: train_loss = 2.270, train_acc = 0.898\n",
            "tensor(2.0321, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0548, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0393, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0184, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0771, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1014, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1116, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1303, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9766, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9974, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0354, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0315, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1101, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1486, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0626, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9792, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1029, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0644, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9920, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1309, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1258, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1011, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0471, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0446, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9546, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9525, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9434, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9296, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0157, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.7157, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6992, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.7148, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.7252, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.7391, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: train_loss = 2.144, train_acc = 0.905\n",
            "tensor(1.8958, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9128, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9234, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9201, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9709, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9587, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9828, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9978, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8517, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8946, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9317, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9276, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0145, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0418, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9412, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8472, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9853, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9399, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8616, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0209, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0255, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9898, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9371, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9260, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8431, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8388, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8316, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8162, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9118, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6298, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6171, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6252, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6362, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.6445, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: train_loss = 2.032, train_acc = 0.918\n",
            "tensor(1.7919, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8099, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8465, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8479, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8873, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8636, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9006, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9055, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7549, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8040, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8508, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8451, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9170, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9694, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8481, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7494, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8978, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8530, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7673, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9515, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9612, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9152, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8603, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8402, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7715, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7724, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7583, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7402, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8327, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5469, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5381, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5427, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5555, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5586, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: train_loss = 1.949, train_acc = 0.927\n",
            "tensor(1.7228, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7402, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7972, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8095, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8377, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7985, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8475, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8525, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7025, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7512, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8007, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7955, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8756, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9171, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7865, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.6955, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8432, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7924, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7120, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8859, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8999, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8726, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8130, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7898, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7144, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7017, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.6984, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.6887, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7786, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.4682, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.4599, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.4655, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.4749, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.4809, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: train_loss = 1.890, train_acc = 0.935\n",
            "tensor(1.6894, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7070, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7617, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7740, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8063, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7632, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8212, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8170, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.6700, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7216, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7696, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7621, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8403, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9009, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7421, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.6515, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8011, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7508, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.6707, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8477, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8565, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.8324, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7715, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.7452, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.6753, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.6634, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.6600, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6534, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7414, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.4025, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3950, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3980, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.4080, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.4084, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: train_loss = 1.849, train_acc = 0.939\n",
            "tensor(1.6637, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6783, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7361, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7474, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7841, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7389, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7991, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7989, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6455, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6969, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7433, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7437, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8115, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8569, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7122, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6239, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7694, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7209, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6430, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8092, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8226, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8051, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7432, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7201, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6517, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6382, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6353, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6299, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7134, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3487, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3438, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3439, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3562, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3545, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: train_loss = 1.819, train_acc = 0.942\n",
            "tensor(1.6469, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6621, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7190, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7349, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7665, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7223, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7864, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7822, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6289, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6812, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7264, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7194, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7925, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8326, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6897, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6069, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7493, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6991, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6241, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7840, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8000, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7817, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7227, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6995, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6348, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6215, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6191, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6139, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6958, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3097, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3062, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3063, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3148, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3118, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: train_loss = 1.797, train_acc = 0.945\n",
            "tensor(1.6304, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6451, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7006, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7118, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7518, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7049, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7720, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7691, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6183, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6678, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7179, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7083, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7768, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8226, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6730, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5948, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7331, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6807, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6143, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7651, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7849, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7635, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7073, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6876, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6239, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6118, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6081, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6032, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6853, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2795, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2774, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2766, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2864, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2786, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: train_loss = 1.780, train_acc = 0.947\n",
            "tensor(1.6184, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6353, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6912, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6970, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7399, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6965, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7643, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7587, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6073, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6554, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7013, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6975, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7705, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8068, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6590, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5855, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7219, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6662, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6071, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7521, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7712, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7511, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6982, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6775, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6157, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6029, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5997, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5966, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6743, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2581, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2579, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2539, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2654, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2576, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: train_loss = 1.768, train_acc = 0.948\n",
            "tensor(1.6097, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6246, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6777, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6908, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7347, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6889, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7588, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7533, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6019, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6552, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6943, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6903, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7628, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7980, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6523, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5807, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7176, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6595, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5983, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7449, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7647, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7446, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6960, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6716, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6096, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5977, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5973, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5900, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6699, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2468, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2459, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2411, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2537, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2453, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: train_loss = 1.761, train_acc = 0.949\n",
            "tensor(1.6057, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6210, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6716, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6861, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7292, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6826, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7539, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7488, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6009, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6470, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6897, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6884, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7573, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7936, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6467, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5774, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7116, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6552, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5973, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7396, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7586, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7425, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6894, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6681, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6075, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5951, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5924, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5882, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6670, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2384, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2394, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2380, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2470, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch 20: train_loss = 1.756, train_acc = 0.949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Create an index array for the epochs\n",
        "epochs = np.arange(len(train_loss_values))\n",
        "\n",
        "# Create two subplots, one for train loss and one for train accuracy\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "\n",
        "# Plot the train loss values on the first subplot\n",
        "ax1.plot(epochs, metrics['train_loss'])\n",
        "ax1.set_title('Train Loss')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "\n",
        "# Plot the train accuracy values on the second subplot\n",
        "ax2.plot(epochs, metrics['train_acc'])\n",
        "ax2.set_title('Train Accuracy')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "MoiUPXWFgKrT",
        "outputId": "4fa104bc-cf30-4d81-873e-9a6795d409e8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/model/* /content/drive/MyDrive/Tugas_Akhir/model/"
      ],
      "metadata": {
        "id": "RLHodVy3gKua"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the finetuned model State_Dict to the Pretrained GPT-J Model\n",
        "\n",
        "import random\n",
        "from prettytable import PrettyTable\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "table = PrettyTable()\n",
        "table.field_names = [\"Prompt\", \"Generated Commands\", \"Correct Command\", \"Similarity (%)\"]\n",
        "\n",
        "network1 = [\"192.168.7.0\", \"192.168.50.0\", \"192.168.32.0\", \"192.168.40.0\"]\n",
        "\n",
        "network2 = [\"192.168.100.0\", \"192.168.10.0\", \"192.168.2.0\", \"192.168.5.0\"]\n",
        "\n",
        "router = [\"Router A\", \"Router G\", \"Router X\"]\n",
        "\n",
        "interface = [\"G0/2\",\"G1\",\"F0/0/1\",\"F0/3\"]\n",
        "\n",
        "for i in range(1):\n",
        "  current = [random.choice(network1), random.choice(network2), random.choice(router)]\n",
        "  prompt = f\"Buat route static menuju network 192.168.100.10 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0 di Router A\" #@param {type:\"string\"}\n",
        "  correct_command = f\"[{current[2]}] configure terminal, router rip, version 2, network {current[0]}, network {current[1]},  end [eoc]<|endoftext|>\" #@param {type:\"string\"}\n",
        "  with torch.no_grad():\n",
        "    tokenized_prompt = tokenizer(f\"prompt:{prompt},commands:[\", truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "    for i in range(2):\n",
        "      tokenized_prompt = {key: value.to(device) for key, value in tokenized_prompt.items()}\n",
        "      out = gpt.generate(**tokenized_prompt, max_length=128, top_k=50, top_p=0.9, temperature=1.0, do_sample=True, repetition_penalty = 1.2, num_beams=1)\n",
        "      outputs = tokenizer.decode(out[0]).split(\",\")\n",
        "      outputs[1] = outputs[1].replace('\\n',', ')\n",
        "      similarity = SequenceMatcher(None, outputs[1].replace('commands:',''), correct_command).ratio() * 100\n",
        "      row = [prompt, outputs[1].replace('commands:',''), correct_command, f\"{similarity:.2f}%\"]\n",
        "      table.add_row(row)\n",
        "\n",
        "print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HbMxsHEmhV4",
        "outputId": "4e0d2b8a-48ab-4428-92cf-53136477cc3a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------+----------------+\n",
            "|                                                         Prompt                                                         |                                     Generated Commands                                    |                                                      Correct Command                                                       | Similarity (%) |\n",
            "+------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------+----------------+\n",
            "| Buat route static menuju network 192.168.100.10 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0 di Router A |                   [Router A] configure terminal, intg g/0/1<|endoftext|>                  | [Router G] configure terminal, router rip, version 2, network 192.168.40.0, network 192.168.100.0,  end [eoc]<|endoftext|> |     55.68%     |\n",
            "| Buat route static menuju network 192.168.100.10 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0 di Router A | [RouterA] configure terminal, interface Gi/0/0/0 enable, encapsulation dot1q<|endoftext|> | [Router G] configure terminal, router rip, version 2, network 192.168.40.0, network 192.168.100.0,  end [eoc]<|endoftext|> |     54.03%     |\n",
            "+------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------+----------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "input = f\"Buat route static menuju network 192.168.100.10 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0 di Router A\" #@param {type:\"string\"}\n",
        "gpt.eval()\n",
        "prompt = f\"prompt:{input},commands:[\"\n",
        "with torch.no_grad():\n",
        "  preprocessed_prompt = tokenizer(prompt, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
        "  preprocessed_prompt = {key: value.to(device) for key, value in preprocessed_prompt.items()}\n",
        "  out = gpt.generate(**preprocessed_prompt, max_length=128, top_k=50, top_p=0.9, temperature=1.0, do_sample=True, repetition_penalty = 1.2, num_beams=1)\n",
        "  outputs = tokenizer.decode(out[0]).split(\",\")\n",
        "  full_commands = outputs[1].replace('\\n',',')\n",
        "\n",
        "  print(full_commands)\n",
        "\n",
        "  prompt = f\"{outputs[1].replace('<|endoftext|>','')},bot_reply:\"\n",
        "  preprocessed_prompt = tokenizer(prompt, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
        "  preprocessed_prompt = {key: value.to(device) for key, value in preprocessed_prompt.items()}\n",
        "  out = gpt.generate(**preprocessed_prompt, max_length=512, top_k=50, top_p=0.9, temperature=1.0, do_sample=True, repetition_penalty = 1.2, num_beams=1)\n",
        "  outputs = tokenizer.decode(out[0])\n",
        "\n",
        "  pattern = r\"bot_reply:(.*)\"\n",
        "  matches = re.findall(pattern, outputs, re.DOTALL)\n",
        "  bot_reply_text = matches[0].strip()\n",
        "  bot_reply = bot_reply_text.replace(\"\\n\",\",\")\n",
        "\n",
        "  print(f'bot_reply:{bot_reply}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pcUfUP_gN6Z",
        "outputId": "4f478e17-a7d3-4862-9f89-9f4735221230"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "commands:[Router B] configure terminal,iproute[–Cocurrentaan adalah IPv4 address 192.168.1.2<|endoftext|>\n",
            "bot_reply:Ada jalanan ini mengaktifkan semua layer sekuriti NAT untuk menyimpan<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kny-0JIgN9E",
        "outputId": "6b246ae8-5cd2-49a1-af72-efb3b95e5375"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['prompt:Buat route static menuju network 192.168.100.10 dengan subnet mask 255.255.255.0 melalui interface g/0/0/0 di Router A', 'commands:[RouterA] configure terminal, interface Gi/0/0/0 enable, encapsulation dot1q<|endoftext|>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "data = [table.field_names] + [[str(cell).strip() for cell in row] for row in table._rows]\n",
        "\n",
        "# Write the data to a CSV file\n",
        "filename = \"table.csv\"\n",
        "with open(filename, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(data)\n",
        "\n",
        "print(f\"Table successfully converted to {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdFq8eU5gOE0",
        "outputId": "a50a94c1-86aa-42b8-dc55-d80ddb4ca89d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table successfully converted to table.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3kEKPbCUpJsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aj1CAofqpJ2Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}